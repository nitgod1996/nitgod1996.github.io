



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="../images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="../images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="宁理大神1996" href="https://nitgod1996.com/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="宁理大神1996" href="https://nitgod1996.com/atom.xml" />
<link rel="alternate" type="application/json" title="宁理大神1996" href="https://nitgod1996.com/feed.json" />



<link rel="stylesheet" href="../css/app.css?v=0.2.5">

  
  <meta name="keywords" content="算法,Python,机器学习" />


<link rel="canonical" href="https://nitgod1996.com/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">



  <title>
西瓜书复习及其部分代码实现 - 笔记 |
nitgod1996 = 宁理大神 1996</title>
<meta name="generator" content="Hexo 5.4.0"><link rel="stylesheet" href="/css/prism.css" type="text/css"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">西瓜书复习及其部分代码实现
  </h1>
  
<div class="meta">
  <span class="item" title="创建时间：2021-06-10 19:20:23">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">发表于</span>
    <time itemprop="dateCreated datePublished" datetime="2021-06-10T19:20:23+08:00">2021-06-10</time>
  </span>
  <span class="item" title="本文字数">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">本文字数</span>
    <span>33k</span>
    <span class="text">字</span>
  </span>
  <span class="item" title="阅读时长">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">阅读时长</span>
    <span>30 分钟</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="切换导航栏">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">nitgod1996</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gicis081o9j20zk0m8dmr.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gipew28b65j20zk0m8hdt.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giph47e9vtj20zk0m8x6l.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giph4wqtg4j20zk0m8x6p.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1giclfw2t96j20zk0m8x6p.jpg"></li>
          <li class="item" data-background-image="https://tva3.sinaimg.cn/large/6833939bly1gicljgocqbj20zk0m8e81.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="../../../../index.html">首页</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="../../../../categories/note/" itemprop="item" rel="index" title="分类于 笔记"><span itemprop="name">笔记</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="https://nitgod1996.com/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="../../../../images/avatar.jpg">
    <meta itemprop="name" content="宁理大神1996">
    <meta itemprop="description" content=", 宁理大神的个人博客">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="宁理大神 1996">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h1 id="数学符号"><a href="#数学符号" class="headerlink" title="数学符号"></a>数学符号</h1><ul>
<li><code>argmin</code>：表示函数取最小值时自变量的集合</li>
</ul>
<h1 id="一-绪论"><a href="#一、-绪论" class="headerlink" title="一、 绪论"></a>一、 绪论</h1><h2 id="1-基本术语及概念"><a href="#1-基本术语及概念" class="headerlink" title="1. 基本术语及概念"></a>1. 基本术语及概念</h2><ul>
<li><strong>特征(feature)<strong>：样本的某个</strong>属性</strong>。</li>
<li><strong>属性空间/样本空间</strong>：一条属性是一个<strong>维度</strong>，n条属性看作是<strong>n维空间</strong>。每个样本可以在该空间找到自己的<strong>坐标</strong></li>
<li><strong>维数</strong>：样本的特征/属性数</li>
<li>**数据集(dataSet)**：一组样本</li>
<li><strong>标记</strong>：训练样本的<strong>结果</strong>。如西瓜是好瓜还是坏瓜。</li>
<li>**样例(example)**：拥有标记信息的示例 </li>
<li><strong>分类(classificaation)/回归(regression)<strong>：预测</strong>离散值</strong>为分类，如好瓜、坏瓜；预测<strong>连续值</strong>为回归，如成熟度0.95</li>
<li><strong>最小二乘</strong>：最小二乘法是一种数学优化技术，它通过<strong>最小化误差的平方和</strong>找到一组数据的<strong>最佳函数</strong>匹配。<ul>
<li>几何意义：求一条线使得所有点到该线的<strong>距离平方和</strong>最小</li>
</ul>
</li>
<li><strong>权重ω：</strong>代表各参数的<strong>重要性</strong></li>
<li><strong>偏置b：</strong>在神经网络中表示该神经元被激活的<strong>容易程度</strong>；</li>
<li><strong>激活函数：</strong>神经网络中，将每层输入信号(a=wx+b)转换为输出信号，其作用是决定该神经元是否被激活</li>
</ul>
<h2 id="2-激活函数"><a href="#2-激活函数" class="headerlink" title="2. 激活函数"></a>2. 激活函数</h2><p>有下激活函数所示，绝大多数激活函数在特定范围为0，即不被激活，也就意味着该神经元对后序网络没有信息传递</p>
<h3 id="21-阶跃函数"><a href="#2-1-阶跃函数" class="headerlink" title="2.1 阶跃函数"></a>2.1 阶跃函数</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220755046.png" alt="image-20210621220755046"></p>
<h3 id="22-sigmoid函数"><a href="#2-2-sigmoid函数" class="headerlink" title="2.2 sigmoid函数"></a>2.2 sigmoid函数</h3><p>​     <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220802439.png" alt="image-20210621220802439"></p>
<h3 id="23-relu函数"><a href="#2-3-ReLU函数" class="headerlink" title="2.3 ReLU函数"></a>2.3 ReLU函数</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220811079.png" alt="image-20210621220811079"></p>
<h3 id="24-softmax函数最后一层输出层的激活函数"><a href="#2-4-softmax函数（最后一层输出层的激活函数）" class="headerlink" title="2.4 softmax函数（最后一层输出层的激活函数）"></a>2.4 softmax函数（最后一层输出层的激活函数）</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220818680.png" alt="image-20210621220818680"></p>
<h3 id="25-函数图"><a href="#2-5-函数图" class="headerlink" title="2.5 函数图"></a>2.5 函数图</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220826903.png" alt="image-20210621220826903">其中：深蓝色的是relu，虚线是阶跃函数，蓝绿色的是sigmod函数</p>
<h2 id="3-梯度下降法"><a href="#3-梯度下降法" class="headerlink" title="3. 梯度下降法"></a>3. 梯度下降法</h2><p><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210710171023412.png" alt="image-20210710171023412">θ是属性集合，在一维函数是x，二维函数一般是x、y</p>
<p>因为是往梯度负方向走，所以是减法</p>
<h2 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbm9sdXllL3AvMTExMDg1MTMuaHRtbA==">https://www.cnblogs.com/noluye/p/11108513.html</span></p>
<h2 id="缺点"><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h2><p>​    可能会因为梯度过小，无法收敛，如下图(x,y)=(3,-3)时</p>
<h2 id="代码实现"><a href="#代码实现：" class="headerlink" title="代码实现："></a>代码实现：</h2><p>以f(x,y)=−e−(x2+y2)为例</p>
<h4 id="1-定义目标函数"><a href="#1-定义目标函数" class="headerlink" title="1. 定义目标函数"></a>1. 定义目标函数</h4><pre><code>def func_2d(x):
    :param x: 自变量，一维数组x[]
    :return: 因变量，标量y
    return - math.exp(-(x[0] ** 2 + x[1] ** 2))
</code></pre>
<h4 id="2-求出梯度函数"><a href="#2-求出梯度函数" class="headerlink" title="2. 求出梯度函数"></a>2. 求出梯度函数</h4><pre><code>def grad_2d(x):
    :param x: 自变量，二维向量
    :return: 因变量，二维向量
    deriv0 = 2 * x[0] * math.exp(-(x[0] ** 2 + x[1] ** 2))
    deriv1 = 2 * x[1] * math.exp(-(x[0] ** 2 + x[1] ** 2))
    return np.array([deriv0, deriv1])    
 
</code></pre>
<h4 id="3-实现梯度下降法"><a href="#3-实现梯度下降法" class="headerlink" title="3. 实现梯度下降法"></a>3. 实现梯度下降法</h4><pre><code>def gradient_descent_2d(grad, cur_x=np.array([0.1, 0.1]), learning_rate=0.01, precision=0.0001, max_iters=10000):
    二维问题的梯度下降法
    :param grad: 目标函数的梯度，以函数传参
    :param cur_x: 起始点，通过参数可以提供初始值
    :param learning_rate: 学习率，也相当于设置的步长（上式α）
    :param precision: 设置收敛精度
    :param max_iters: 最大迭代次数
    :return: 局部最小值 x*
    for i in range(max_iters):
        grad_cur = grad(cur_x) #更新梯度
        if np.linalg.norm(grad_cur, ord=2) &lt; precision:
            break  # 当梯度趋近为 0 时，视为收敛
        cur_x = cur_x - grad_cur * learning_rate#迭代自变量
 
公式：
 

        print(&quot;第&quot;, i, &quot;次迭代：x 值为 &quot;, cur_x)

    print(&quot;局部最小值 x =&quot;, cur_x)
    return cur_x
</code></pre>
<h1 id="二-模型评估与选择"><a href="#二、-模型评估与选择" class="headerlink" title="二、 模型评估与选择"></a>二、 模型评估与选择</h1><h2 id="1-误差与过拟合"><a href="#1-误差与过拟合" class="headerlink" title="1. 误差与过拟合"></a>1. 误差与过拟合</h2><ul>
<li><strong>训练误差/经验误差</strong>：学习器在训练集上的误差</li>
<li><strong>泛化误差</strong>：在<strong>新样本</strong>（不知道的样本）上的误差</li>
</ul>
<p>在建立学习器时，我们往往使用一组样本，将其分为训练样本和测试样本，训练和测试用的是同一样本。</p>
<p>精度accuracy是学习器预测结果相较于测试样本标记的正确率，当测试样本足够大时，精确到可能能到100%，但会造成<strong>过拟合</strong>。</p>
<p>因为我们希望是学习器在<strong>新样本</strong>上的预测效果好，而非是训练和测试的样本</p>
<ul>
<li><strong>过拟合</strong>：对训练样本<strong>非一般</strong>的特征学习，导致泛化能力不足。</li>
</ul>
<h2 id="2-评估方法"><a href="#2-评估方法" class="headerlink" title="2. 评估方法"></a>2. 评估方法</h2><p>我们对学习器的<strong>泛化误差</strong>进行评估，以此来评价这个学习器的好坏</p>
<h1 id="三-线性模型"><a href="#三、-线性模型" class="headerlink" title="三、 线性模型"></a>三、 线性模型</h1><blockquote>
<p>这里是开始的重点，主要是线性回归和逻辑回归</p>
</blockquote>
<ul>
<li><strong>线性模型</strong>：通过属性的线性组合来进行预测<br>$$<br>f(x)=w_1x_1+w_2x_2+…+w_dx_d+b<br>$$<br>用向量形式，写成<br>$$<br>f(\boldsymbol{x})=\boldsymbol{w}^T\boldsymbol{x}+b<br>$$<br>其中，<code>x</code>：属性，<code>w</code>：属性<strong>权重</strong>，<code>b</code>：偏移</li>
</ul>
<p>因此，只需**求出<code>w=(w1,w2..)</code>和<code>b</code>**，模型即可确定。而几何意义上看是一条直线把样本分成了2个阵营（二分类）</p>
<ul>
<li><strong>最小二乘</strong>：最小二乘法是一种数学优化技术，它通过<strong>最小化误差的平方和</strong>找到一组数据的<strong>最佳函数</strong>匹配。<ul>
<li>几何意义：求一条线使得所有点到该线的<strong>距离平方和</strong>最小</li>
</ul>
</li>
</ul>
<h2 id="1-线性回归linear-regression"><a href="#1-线性回归（linear-regression）" class="headerlink" title="1. 线性回归（linear regression）"></a>1. 线性回归（linear regression）</h2><p>回归一般用于预测<strong>连续值</strong></p>
<h3 id="11-算法原理"><a href="#1-1-算法原理" class="headerlink" title="1.1 算法原理"></a>1.1 算法原理</h3><p>试图通过学得一个<strong>线性模型</strong>来预测数据<br>$$<br>f(\boldsymbol{x})=\boldsymbol{w}^T\boldsymbol{x}+b\tag{1.1}<br>$$</p>
<blockquote>
<p>所以，只需求出<strong>权重w</strong>和<strong>偏移b</strong>，即可得出线性模型</p>
</blockquote>
<h4 id="111-单属性线性回归"><a href="#1-1-1-单属性线性回归" class="headerlink" title="1.1.1 单属性线性回归"></a>1.1.1 单属性线性回归</h4><p>当每条样本仅有一个属性时：</p>
<p>对于每条样本数据的预测，即为<br>$$<br>f({x_i})={w_i}{x_i}+b,使得f(x_i)\simeq y_i\tag{1.2}<br>$$<br>其中，<code>f(x)</code>是是样本的<strong>预测数据</strong>。<code>yi</code>是样本的<strong>测试数据</strong>，<code>f(x)</code>应尽量趋近<code>y</code></p>
<p>最常用的是通过<strong>均方误差最小化</strong>来求<code>w</code>和<code>b</code>，也称<strong>欧几里得距离</strong>，是L0范数<br>$$<br>\DeclareMathOperator*{\argmin}{argmin}<br>(w^*,b^*)=\argmin\limits_{(w,b)}\sum_{i=1}^{m}(f(x_i)-y_i)^2=\argmin\limits_{(w,b)}\sum_{i=1}^{m}(y_i-wx_i-b)^2\tag{1.3}<br>$$<br>公式(1.3)的意思是：f(xi)和yi均方差取最小时(w,b)的集合</p>
<blockquote>
<p>基于均方误差最小化进行模型求解的方法成为<strong>最小二乘法</strong></p>
<p>几何意义：找一条直线使所有样本到该直线的欧氏距离之和最小。如物理实验的描点画直线</p>
</blockquote>
<p>对公式(1.3)求最小化时自变量<code>w</code>和<code>b</code>的取值，称为线性回归的最小二乘<strong>参数估计</strong>。</p>
<p>分别对<code>w</code>和<code>b</code>求偏导，令偏导为0即可求出<code>w</code>和<code>b</code>的取值</p>
<h4 id="112-多元线性回归"><a href="#1-1-2-多元线性回归" class="headerlink" title="1.1.2 多元线性回归"></a>1.1.2 多元线性回归</h4><p>当每条样本有n条属性时，<code>w</code>和<code>x</code>是矩阵形式，<code>y</code>也是向量形式</p>
<blockquote>
<p><strong>X</strong>是数据集，最后一个元素恒置1；<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/20170817104340827" alt="这里写图片描述"></p>
<p><strong>y</strong>是样本标记<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210610202842085.png" alt="image-20210610202842085"></p>
</blockquote>
<p>预测模型即为<br>$$<br>f(\boldsymbol{x_i})=\boldsymbol{w}^T\boldsymbol{x_i}+b,使得f(x_i)\simeq y_i\tag{1.4}<br>$$<br>为方便讨论将<strong>ω</strong>和<strong>b</strong>写在一起，如下。<br>$$<br>\widehat{w}=(w;b)\tag{1.5}<br>$$<br>此处省略推导过程，利用<strong>最小二乘法</strong>对<strong>ω</strong>和<strong>b</strong>进行估计，得出<br>$$<br>\boldsymbol{\widehat{w}^*=(X^TX)^{-1}X^Ty}\tag{1.6}<br>$$</p>
<p>那么线性回归模型即为<br>$$<br>f(\widehat{\boldsymbol{x}}<em>i)=\widehat{\boldsymbol{x}}</em>{i}^{T}\boldsymbol{(X^TX)^{-1}X^Ty}\tag{1.7}<br>$$<br>然而<strong>X</strong>常常<strong>不满秩</strong>，如变量数超过样本数。此时可解出多个解，<strong>均能使均方误差最小化</strong>。此时选择哪个解由算法偏好决定，常见的是引入<strong>正则化</strong></p>
<p><strong>总结</strong>：</p>
<p>​        就是通过一顿操作求出了样本每个特征的<strong>权重</strong>和<strong>偏移</strong>（<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210610211038636.png" alt="image-20210610211038636">)，然后通过它预测<strong>新样本</strong>。线性回归的<strong>学习器</strong>就是<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210610211038636.png" alt="image-20210610211038636"></p>
<p>​        类似于物理实验描点画直线，最终得到<strong>学习模型（学习器）</strong>。只不过这里是多元的直线<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/u=3884380577,2563057688&fm=15&gp=0.jpg" alt="img"></p>
<h3 id="12-python代码实现"><a href="#1-2-Python代码实现" class="headerlink" title="1.2 Python代码实现"></a>1.2 Python代码实现</h3><blockquote>
<p>Python有装门用于机器学习的sklearn库，可直接利用</p>
</blockquote>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1. 读取数据</span>
dataset <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'F:\project\watermelon\melon_data1.csv'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2. 定义样本属性和训练目标，此例是用密度预测含糖率</span>
X <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'密度'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#其中属性值是二维向量：n个样本;n个属性/样本</span>
Y <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">'含糖率'</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#3. 切分训练集和验证集</span>
X_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span>Y_train<span class="token punctuation">,</span>Y_test <span class="token operator">=</span> model_selection<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#4. 建立模型</span>
log_model <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#5. 训练</span>
log_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>Y_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#6. 预测</span>
Y_pred <span class="token operator">=</span> log_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#7. 评估（此处用均方差）</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>Y_pred<span class="token operator">-</span>Y_test<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
<p><strong>关于sklearn.linear_model.LinearRegression</strong></p>
<p>已知线性模型是<br>$$<br>f(\boldsymbol{x})=\boldsymbol{w}^T\boldsymbol{x}+b<br>$$<br>其中：</p>
<p>​    -<code>w</code>是权重，表示特征的重要程度。一维向量</p>
<p>​    -<code>b</code>是偏置，模型的偏移量。单个数值</p>
<p>​    -<code>x</code>是样本，一组特征值。一维向量</p>
<pre class=" language-python"><code class="language-python">LinearRegression<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">,</span> fit_intercept<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> copy_X<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span>None<span class="token punctuation">,</span> positive<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token triple-quoted-string string">"""
       创建线性回归模型，以下参数均为可选，一般来说都选默认值
    :param fit_intercept: bool, default=True.是否计算此模型的截距b。如果设置为False，则在计算中不使用截距（即数据应居中）。
    :param normalize: bool, default=False。如果为真，回归系数X将在回归前通过减去平均值并除以l2范数进行归一化。
    :param copy_X: bool, default=True。如果为True，则复制X；否则，它可能会被覆盖。
    :param n_jobs: int, default=None。用于计算的作业数。
    :param positive: bool, default=False。设置为True时，强制系数为正。只有密集阵列才支持此选项。
    :return: sklearn.linear_model._logistic.LogisticRegression
    """</span>
</code></pre>
<p>函数<code>LinearRegression()</code>返回一个<code>LogisticRegression</code>对象。</p>
<p><strong>常用属性（成员变量）：</strong></p>
<ul>
<li><code>coef_</code>：<strong>array</strong>。（系数），指的是权重<code>w</code></li>
<li><code>intercept_ </code>：<strong>float</strong>。模型的偏置<code>b</code></li>
</ul>
<p><strong>常用函数：</strong></p>
<ul>
<li><code>fit(X, y, sample_weight=None)</code>：拟合线性模型（以最小二乘法，即求最小均方差）。<ul>
<li><code>X</code>：训练样本特征值。二维数组（行-样本，列-特征）</li>
<li><code>y</code>：靶值。一维数组，样本的结果值</li>
<li><code>sample_weight</code>：每个样品的单独重量（暂时不清楚，可能是属性的权重2？）</li>
<li><strong>return：</strong>self。返回拟合后的线性模型，这种不需要去接收，属于修改型的函数</li>
</ul>
</li>
<li><code>predict(X)</code>：预测<ul>
<li><code>X</code>：用于预测的样本</li>
<li><strong>return：</strong>array。样本的预测值 </li>
</ul>
</li>
<li><code>get_params(deep=True)</code>：以字典形式返回模型参数，包括但不限于<code>fit_intercept</code><ul>
<li><code>deep</code>：如果为True，则将返回此估计器的参数以及作为估计器的包含子对象。</li>
<li><strong>return：</strong>dict</li>
</ul>
</li>
<li><code>set_params(**params)</code>：设置参数<ul>
<li><code>**params</code>：dict</li>
</ul>
</li>
</ul>
<h2 id="2-对数几率回归逻辑回归"><a href="#2-对数几率回归（逻辑回归）" class="headerlink" title="2. 对数几率回归（逻辑回归）"></a>2. 对数几率回归（逻辑回归）</h2><p>虽然叫作<strong>回归</strong>，但逻辑回归是<strong>分类器</strong></p>
<h3 id="21-与线性回归的区别"><a href="#2-1-与线性回归的区别" class="headerlink" title="2.1 与线性回归的区别"></a>2.1 与线性回归的区别</h3><blockquote>
<p>逻辑回归和线性回归一样，都是求ω和b。即学习器均是β=(ω:b)</p>
</blockquote>
<p><strong>liner回归：</strong></p>
<pre><code> 1. 主要学习**线性模型**。
 2. 预测一般是预测该样本在线性模型上的取值（当然取值也可以看做分类）
</code></pre>
<p><strong>logic回归：</strong></p>
<ol>
<li>通过学习后的<strong>模型</strong>对新样本进行<strong>分类</strong>。</li>
<li>主要通过<strong>跃迁函数（sigmod）</strong>加强分类效果。</li>
</ol>
<h3 id="22-sigmod函数"><a href="#2-2-sigmod函数" class="headerlink" title="2.2 sigmod函数"></a>2.2 sigmod函数</h3><p><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621165221963.png" alt="image-20210621165221963"><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621170226764.png" alt="image-20210621170226764"></p>
<p>意义：大于0判正，大于0判负</p>
<blockquote>
<p>因为单位阶跃函数不连续，所以用sigmod函数（对数几率函数logistic function）替代，因此称为对数几率回归/逻辑回归</p>
</blockquote>
<h3 id="23-算法原理"><a href="#2-3-算法原理" class="headerlink" title="2.3 算法原理"></a>2.3 算法原理</h3><p>与线性回归稍有不同，这是用于<strong>分类</strong>学习的算法，目标值是离散的</p>
<p><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621163134066.png" alt="image-20210621163134066"></p>
<p>​    其公式是线性回归和跃迁函数的结合</p>
<ol>
<li><p>线性函数<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621171121845.png" alt="image-20210621171121845">与<em>sigmod</em>函数<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621165221963.png" alt="image-20210621165221963">结合→<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621163134066.png" alt="image-20210621163134066"></p>
</li>
<li><p>推出<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621171318629.png" alt="image-20210621171318629">，y以0.5为临界点</p>
</li>
<li><p>得出极大似然函数<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621171854071.png" alt="image-20210621171854071">。求出其取<strong>最小值</strong>时<em>β</em>的取值即为模型解参数</p>
<blockquote>
<p>其中，<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621172030205.png" alt="image-20210621172030205"></p>
</blockquote>
</li>
</ol>
<p>可以<strong>梯度下降法</strong>或<strong>牛顿法</strong>解</p>
<p>其中关于β的一阶、二阶导数分别为<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621172247380.png" alt="image-20210621172247380">可用来求梯度<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621172300230.png" alt="image-20210621172300230"></p>
<p><strong>总结：</strong>logic回归就是求模型<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621163134066.png" alt="image-20210621163134066">的参数ω和b。</p>
<h3 id="24-代码"><a href="#2-4-代码" class="headerlink" title="2.4 代码"></a>2.4 代码</h3><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1. 读取数据</span>
dataset <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'F:\project\watermelon\melon_data1.csv'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2. 定义样本属性和训练目标，此例是用密度预测含糖率</span>
X <span class="token operator">=</span> dataset<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'密度'</span><span class="token punctuation">,</span><span class="token string">'含糖率'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#其中属性值是二维向量：n个样本;n个属性/样本</span>
Y <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">'含糖率'</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#3. 切分训练集和验证集</span>
X_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span>Y_train<span class="token punctuation">,</span>Y_test <span class="token operator">=</span> model_selection<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#4. 建立模型</span>
log_model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#逻辑回归，就是对数线性回归，离散分类</span>
<span class="token comment" spellcheck="true">#5. 训练</span>
log_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>Y_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#6. 预测</span>
Y_pred <span class="token operator">=</span> log_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#7. 评估（此处用精确度，即预测到到的/没预测到的）</span>
<span class="token number">1</span><span class="token operator">-</span>sum<span class="token punctuation">(</span>Y_pred<span class="token operator">-</span>Y_test<span class="token punctuation">)</span><span class="token operator">/</span>len<span class="token punctuation">(</span>Y_test<span class="token punctuation">)</span>
</code></pre>
<p><strong>关于sklearn.linear_model.LogisticRegression</strong></p>
<p>已知逻辑回归模型<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621163134066.png" alt="image-20210621163134066"></p>
<p>其中：</p>
<p>​    -<code>w</code>是权重，表示特征的重要程度。一维向量</p>
<p>​    -<code>b</code>是偏置，模型的偏移量。单个数值</p>
<p>​    -<code>x</code>是样本，一组特征值。一维向量</p>
<pre class=" language-python"><code class="language-python">LogisticRegression<span class="token punctuation">(</span>penalty<span class="token operator">=</span><span class="token string">'l2'</span><span class="token punctuation">,</span> <span class="token operator">*</span><span class="token punctuation">,</span> dual<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> C<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> fit_intercept<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> intercept_scaling<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> class_weight<span class="token operator">=</span>None<span class="token punctuation">,</span> random_state<span class="token operator">=</span>None<span class="token punctuation">,</span> solver<span class="token operator">=</span><span class="token string">'lbfgs'</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> multi_class<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> warm_start<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span>None<span class="token punctuation">,</span> l1_ratio<span class="token operator">=</span>None<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#虽然有这么多的参数，但一般默认就行</span>
log_model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#直接这样就行</span>
</code></pre>
<p>函数<code>LogisticRegression()</code>返回一个<code>LogisticRegression</code>对象。</p>
<p><strong>常用属性（成员变量）：</strong></p>
<ul>
<li><code>coef_</code>：<strong>array</strong>。（系数），指的是权重<code>w</code></li>
<li><code>intercept_ </code>：<strong>float</strong>。模型的偏置<code>b</code></li>
<li><code>classes_ </code>：<strong>ndarray</strong>。分类器已知的类标签列表（逻辑回归可以是多分类）</li>
<li><code>n_iter_</code>：<strong>ndarray</strong> 。各分类的实际<strong>迭代次数</strong>。</li>
</ul>
<p><strong>常用函数：</strong></p>
<ul>
<li><code>fit(X, y, sample_weight=None)</code>：拟合模型。</li>
<li><code>predict(X)</code>：预测</li>
<li><code>get_params(deep=True)</code>：以字典形式返回模型参数，包括但不限于<code>fit_intercept</code></li>
<li><code>set_params(**params)</code>：设置参数</li>
<li><code>decision_function(X)</code>：预测样本的置信度。样本的置信度与样本到超平面的有符号距离成正比。</li>
</ul>
<h1 id="四-决策树"><a href="#四、-决策树" class="headerlink" title="四、 决策树"></a>四、 决策树</h1><p>决策树主要就是靠计算<strong>信息增益</strong>或<strong>基尼指数</strong>决定选哪条支线，属于<strong>分类</strong>算法。</p>
<h1 id="五-神经网络初阶"><a href="#五、-神经网络初阶" class="headerlink" title="五、 神经网络初阶"></a>五、 神经网络初阶</h1><blockquote>
<p>神经网络这块西瓜书讲得不是很详细，而且神经网络本来就是不小于机器学习的模块，所以我这里主要参考了别的一些专门讲<strong>深度学习</strong>的书。</p>
</blockquote>
<p>参考：《深度学习入门<em>基于python的理论与实现</em>》</p>
<p>神经网络是个层次递进的结构，每层通过一定的函数计算到下一层，如图所示</p>
<p><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/neural_network.jpg" alt="neural_network"></p>
<p>在此之前，先来熟悉一下神经网络的一些概念</p>
<ul>
<li><strong>权重ω：</strong>代表各参数的<strong>重要性</strong></li>
<li><strong>偏置b：</strong>在神经网络中表示该神经元被激活的<strong>容易程度</strong>；</li>
<li><strong>激活函数：</strong>神经网络中，将每层输入信号(a=wx+b)转换为输出信号，其作用是决定该神经元是否被激活</li>
<li><strong>张量(tensor)：</strong>神经网络使用的数据存储在<strong>多维Numpy 数组</strong>中，也叫<strong>张量（tensor）</strong>。<font color="red">所以张量其实就是多维数组</font>，之所以不能叫做矩阵，矩阵只是二维的数组，张量所指的维度是没有限制的。一般来说，当前所有机器学习系统都使用张量作为基本数据结构。张量这一概念的核心在于，它是一个<strong>数据容器</strong>。它包含的数据几乎总是<strong>数值数据</strong>，因此它是数字的容器。<strong>矩阵</strong>就是<strong>二维张量</strong>。张量是矩阵向<strong>任意维度</strong>的扩展。</li>
<li><strong>梯度(grad)：</strong>由<strong>全部</strong>变量的<strong>偏导数</strong>汇总而成的<strong>张量</strong>称为**梯度(gradient)**。如grad_xy=(dz/dx,dz/dy)</li>
</ul>
<h2 id="1-激活函数"><a href="#1-激活函数" class="headerlink" title="1. 激活函数"></a>1. 激活函数</h2><p>有下激活函数所示，绝大多数激活函数在特定范围为0，即不被激活，也就意味着该神经元对后序网络没有信息传递</p>
<h3 id="11-阶跃函数"><a href="#1-1-阶跃函数" class="headerlink" title="1.1 阶跃函数"></a>1.1 阶跃函数</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220755046.png" alt="image-20210621220755046"></p>
<h3 id="12-sigmoid函数"><a href="#1-2-sigmoid函数" class="headerlink" title="1.2 sigmoid函数"></a>1.2 sigmoid函数</h3><p>​     <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220802439.png" alt="image-20210621220802439"></p>
<h3 id="13-relu函数"><a href="#1-3-ReLU函数" class="headerlink" title="1.3 ReLU函数"></a>1.3 ReLU函数</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220811079.png" alt="image-20210621220811079"></p>
<h3 id="14-softmax函数最后一层输出层的激活函数"><a href="#1-4-softmax函数（最后一层输出层的激活函数）" class="headerlink" title="1.4 softmax函数（最后一层输出层的激活函数）"></a>1.4 softmax函数（最后一层输出层的激活函数）</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220818680.png" alt="image-20210621220818680"></p>
<h3 id="15-函数图"><a href="#1-5-函数图" class="headerlink" title="1.5 函数图"></a>1.5 函数图</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220826903.png" alt="image-20210621220826903"></p>
<p>其中：深蓝色的是relu，黑色虚线是阶跃函数，蓝绿色的是sigmod函数</p>
<h2 id="2-神经网络的层次递进"><a href="#2-神经网络的层次递进" class="headerlink" title="2. 神经网络的层次递进"></a>2. 神经网络的层次递进</h2><p>如上图：<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/neural_network.jpg" alt="neural_network"></p>
<p>其中<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621221751826.png" alt="image-20210621221751826"></p>
<blockquote>
<p><strong>X</strong>：特征矩阵。<strong>ω</strong>：各属性权重的矩阵。</p>
</blockquote>
<p>注意以下几点：</p>
<ol>
<li><p><strong>输出层</strong>神经元一般取决于<strong>分类数</strong>（几分类就几个），<strong>输入</strong>神经元一般取决于<strong>属性/特征</strong>个数</p>
</li>
<li><p><strong>x-&gt;a(隐藏层)-&gt;输出层</strong>是<strong>矩阵运算</strong></p>
</li>
<li><p><code>x</code>是输入<code>1*n</code>的向量，<code>n</code>代表<strong>特征值数量</strong></p>
</li>
</ol>
<p>​      <code>ω</code>是<code>n*m</code>的权值，行：n个特征值，列：下一层 m个神经元</p>
<p>​      <code>b</code>是<code>1*m</code>的向量（b的每个元素并不一样）</p>
<ol start="4">
<li><p>**激活函数<code>h()</code>**用于隐藏层将输入→输出，及<code>a()→z()</code></p>
</li>
<li><p>输出层的激活函数<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621222800025.png" alt="image-20210621222800025">要视情况而定，</p>
<p>一般而言：</p>
<ul>
<li>回归（连续）：恒等函数（输入即输出）</li>
<li>分类：</li>
</ul>
<p>​       二元分类：<code>sigmoid()</code><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621220802439.png" alt="image-20210621220802439"></p>
<p>​       多分类：<code>softmax()</code><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621223227999.png" alt="image-20210621223227999"></p>
</li>
</ol>
<h2 id="3-神经网络的学习"><a href="#3-神经网络的学习" class="headerlink" title="3. 神经网络的学习"></a>3. 神经网络的学习</h2><blockquote>
<p>模型的学习主要是为了找到合适的**权重<code>ω</code><strong>和</strong>偏置<code>b</code>**。学习的过程就是<code>ω</code>和<code>b</code><strong>更新</strong>的过程</p>
</blockquote>
<p>大致学习过程如下：</p>
<ol>
<li><strong>初始化：</strong>选取初始权重<code>ω</code>和偏置<code>b</code></li>
<li><strong>预测：</strong>根据损失函数求误差</li>
<li><strong>损失函数求梯度：</strong>主要是求关于<strong>权重</strong>的梯度。一般用求导公式或<strong>误差反向传播算法</strong></li>
<li><strong>更新权重：</strong>向损失函数<strong>梯度反方向</strong>更新</li>
<li><strong>预测：</strong>是否满足要求？是→结束；否→继续3,4,5</li>
</ol>
<h3 id="31-特征提取与算法设计"><a href="#3-1-特征提取与算法设计" class="headerlink" title="3.1 特征提取与算法设计"></a>3.1 特征提取与算法设计</h3><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210621223607967.png" alt="image-20210621223607967"></p>
<p>神经网络是没有人为介入，自动提取特征值的。如直接提取图像的本质数据（像素什么的）</p>
<h3 id="32-损失函数"><a href="#3-2-损失函数" class="headerlink" title="3.2 损失函数"></a>3.2 损失函数</h3><ul>
<li><p>用于表示神经网络<strong>优劣</strong>的指标，损失<strong>越小</strong>，神经网络性能越好。类似误差率。</p>
</li>
<li><p>通过不断更新<strong>权重ω</strong>来使损失最小化→以使神经网络最优</p>
<ul>
<li>一般使用<strong>梯度下降法</strong>，沿损失函数<strong>梯度反方向</strong>（损失函数减小的方向）更新权重</li>
<li><strong>梯度</strong>可以直接求导公式求，也可以用<strong>误差反向传播法</strong>求梯度</li>
</ul>
</li>
<li><p>一般用的比较多的损失函数是<strong>均方误差</strong>和<strong>交叉熵误差</strong></p>
</li>
</ul>
<h4 id="321-均方误差"><a href="#3-2-1-均方误差" class="headerlink" title="3.2.1 均方误差"></a>3.2.1 均方误差</h4><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210622160555811.png" alt="image-20210622160555811"></p>
<p><code>yk</code>和<code>tk</code>分别是预测值和实际值，y是长度为n的一维向量</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">mean_squared_error</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    损失函数：均方误差
    :param y: 预测值,np数组
    :param t: 监督值,np数组
    :return: 均方误差float
    """</span>
    <span class="token keyword">return</span> <span class="token number">0.5</span><span class="token operator">*</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">(</span>y<span class="token operator">-</span>t<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="322-交叉熵误差"><a href="#3-2-2-交叉熵误差" class="headerlink" title="3.2.2 交叉熵误差"></a>3.2.2 交叉熵误差</h4><p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210622160932219.png" alt="image-20210622160932219"></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cross_entropy_error</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    损失函数：交叉熵误差
    :param y: 预测值，np数组
    :param t: 监督值,np数组
    :return: 交叉熵误差float
    """</span>
    delta<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span>  <span class="token comment" spellcheck="true">#10的-7次，为了防止log0导致的下溢</span>
    <span class="token keyword">return</span> <span class="token operator">-</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>t<span class="token operator">*</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y<span class="token operator">+</span>delta<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="33-神经网络学习"><a href="#3-3-神经网络学习" class="headerlink" title="3.3 神经网络学习"></a>3.3 神经网络学习</h3><p><strong>步骤：</strong></p>
<ol>
<li><p>抽取mini-batch</p>
</li>
<li><p>计算梯度（权重的梯度）</p>
</li>
<li><p>更新参数（权重，沿梯度反方向更新）</p>
</li>
<li><p>重复123</p>
</li>
</ol>
<p><strong>代码：</strong></p>
<ol>
<li><p>神经网络类</p>
<ol>
<li>初始化权重</li>
<li>预测函数</li>
<li>损失函数</li>
<li>精确率函数</li>
<li>梯度下降函数</li>
</ol>
</li>
<li><p>训练学习类</p>
<ol>
<li>MNIST上导入训练集和数据集</li>
<li>设定学习参数（训练次数、神经网络各层神经元数、小批量样本数、学习率等）</li>
<li>迭代计算，各权重沿自己梯度反方向更新，并保存精度变化</li>
<li>绘制图形</li>
</ol>
</li>
</ol>
<h3 id="34-误差反向传播求梯度"><a href="#3-4-误差反向传播求梯度" class="headerlink" title="3.4 误差反向传播求梯度"></a>3.4 误差反向传播求梯度</h3><p>通过反向传播求得损失函数的梯度（各自变量的导数），然后即可沿梯度反方向<strong>更新权重</strong>。</p>
<p>反向传播可以比较<strong>快</strong>地计算出梯度。</p>
<blockquote>
<p>原理：局部求导</p>
<p>公式：输出梯度=输入梯度*本层导数</p>
</blockquote>
<p>实际上和复合函数求导是一样的道理，图中：上面的是价格，下面的是梯度</p>
<p><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/3.jpg" alt="neural_network"></p>
<h4 id="341-关于affine层的矩阵反向求导"><a href="#3-4-1-关于Affine层的矩阵反向求导" class="headerlink" title="3.4.1 关于Affine层的矩阵反向求导"></a>3.4.1 关于Affine层的矩阵反向求导</h4><p><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210622162354257.png" alt="image-20210622162354257"> </p>
<blockquote>
<p>其中，</p>
<p>​    X：特征值向量（N*m）；</p>
<p>​    W：权重矩阵（m*n）；</p>
<p>​    B：偏移向量（1*n）；</p>
<p>​    Y：输出数组（N*n）</p>
<p>​        N为批量数，因为小批量处理可以输入N组向量输出N组向量，通过矩阵乘法</p>
</blockquote>
<p>反向传播：</p>
<p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210622165007115.png" alt="image-20210622165007115"></p>
<blockquote>
<p> L是损失函数，Y作为loss函数的自变量，<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210622165455298.png" alt="image-20210622165455298">是上游传来的导数</p>
<p> 对于<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210726173859452.png" alt="image-20210726173859452">，W相当于是常数；同理，对于<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/image-20210726173914864.png" alt="image-20210726173914864">，X是常数</p>
</blockquote>
<p><font color="red">Affine层各权重梯度求出后实时保存</font></p>
<p>代码：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Affine</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span>W
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> b
        
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>original_x_shape <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 权重和偏置参数的导数</span>
        self<span class="token punctuation">.</span>dW <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 对应张量（相当于维度，矩阵是二维张量）</span>
        self<span class="token punctuation">.</span>original_x_shape <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x
        out <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        <span class="token keyword">return</span> out
    
    <span class="token comment" spellcheck="true">#反向传播</span>
    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        dout是上游传下来的梯度
        """</span>
        dx <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dW <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># Affine层各权重梯度求出后实时保存</span>
        dx <span class="token operator">=</span> dx<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">*</span>self<span class="token punctuation">.</span>original_x_shape<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 还原输入数据的形状（对应张量）</span>
        <span class="token keyword">return</span> dx
</code></pre>
<h4 id="342-最上游导数生成softmax_with_loss损失函数相对于softmax的输出y的伪梯度矩阵"><a href="#3-4-2-最上游导数生成，softmax-with-loss，损失函数相对于softmax的输出y的伪梯度矩阵" class="headerlink" title="3.4.2 最上游导数生成，softmax_with_loss，损失函数相对于softmax的输出y的伪梯度矩阵"></a>3.4.2 最上游导数生成，softmax_with_loss，损失函数相对于softmax的输出y的伪梯度矩阵</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SoftmaxWithLoss</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    softmax层和loss函数层一起
    其实就是y-l的关系，即最上游的导数求解
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>loss <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> None <span class="token comment" spellcheck="true"># softmax的输出</span>
        self<span class="token punctuation">.</span>t <span class="token operator">=</span> None <span class="token comment" spellcheck="true"># 监督数据</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        得到softmax输出和误差函数输出，还有监督数据
        :param x: 
        :param t: 监督值,np数组
        :return: 交叉熵误差
        """</span>
        self<span class="token punctuation">.</span>t <span class="token operator">=</span> t
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>loss <span class="token operator">=</span> cross_entropy_error<span class="token punctuation">(</span>self<span class="token punctuation">.</span>y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>t<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>loss

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        求dl/dy
        :param dout:
        :return: (y1-t1,y2-t2,y3-t3...)差分数组
        loss中相对于y的梯度，差分数组代表梯度数组，越接近0越精确。各元素往梯度负方向更新即可
        t和y都是多组一维向量组成的二维向量
        """</span>
        batch_size <span class="token operator">=</span> self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>size <span class="token operator">==</span> self<span class="token punctuation">.</span>y<span class="token punctuation">.</span>size<span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 监督数据是one-hot-vector的情况，one-hot-vector就是[0,0,0,0,1,0,0,0,0]表示4</span>
            dx <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>y <span class="token operator">-</span> self<span class="token punctuation">.</span>t<span class="token punctuation">)</span> <span class="token operator">/</span> batch_size
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            dx <span class="token operator">=</span> self<span class="token punctuation">.</span>y<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
            dx<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>t<span class="token punctuation">]</span> <span class="token operator">-=</span> <span class="token number">1</span>
            <span class="token comment" spellcheck="true">#np.arange是0,1,2,3,4,....</span>
            <span class="token comment" spellcheck="true">#t是[]表示的是每个样本（每组特征向量）的监督值</span>
            <span class="token comment" spellcheck="true">#这行的意思是将dx对应行（一行代表一个样本的预测值概率向量）的对应位置（位置是t的监督值，比如监督值为4，对应dx中第5个元素的概率位置）的元素-1</span>
            dx <span class="token operator">=</span> dx <span class="token operator">/</span> batch_size
        
        <span class="token keyword">return</span> dx
</code></pre>
<h4 id="343-反向传播求梯度代码全貌"><a href="#3-4-3-反向传播求梯度代码全貌" class="headerlink" title="3.4.3 反向传播求梯度代码全貌"></a>3.4.3 反向传播求梯度代码全貌</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true">#为什么只要导入x呢，因为自变量W和b都在params中保存着了</span>
    W1<span class="token punctuation">,</span> W2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
    b1<span class="token punctuation">,</span> b2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span>
    grads <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>

    batch_num <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># forward</span>
    a1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W1<span class="token punctuation">)</span> <span class="token operator">+</span> b1
    z1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>
    a2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> b2
    y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>a2<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># backward</span>
    dy <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> t<span class="token punctuation">)</span> <span class="token operator">/</span> batch_num <span class="token comment" spellcheck="true">#差分数组，dy是最上层微分（梯度），是公式中的dl/dy</span>
    grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>z1<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dy<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#公式中的dl/dw</span>
    grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dy<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">#Affine层反向传播的时候沿途就保存权重的梯度了</span>

    da1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dy<span class="token punctuation">,</span> W2<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#X*W+B=Y，a是此式中的X</span>

    dz1 <span class="token operator">=</span> sigmoid_grad<span class="token punctuation">(</span>a1<span class="token punctuation">)</span> <span class="token operator">*</span> da1<span class="token comment" spellcheck="true">#sigmoid层反向传播（sigmoid层是直接求导的）</span>
    grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dz1<span class="token punctuation">)</span>
    grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dz1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> grads
</code></pre>
<h2 id="4-神经网络的代码设计"><a href="#4-神经网络的代码设计" class="headerlink" title="4. 神经网络的代码设计"></a>4. 神经网络的代码设计</h2><blockquote>
<p>y-预测值；t-标签值</p>
<p>x-样本；w-权重；b-偏置</p>
</blockquote>
<h3 id="41-functionpy"><a href="#4-1-function-py" class="headerlink" title="4.1 function.py"></a>4.1 function.py</h3><p>包括各激活函数的、损失函数的实现以及反向传播的局部梯度</p>
<h4 id="411-正向传播"><a href="#4-1-1-正向传播" class="headerlink" title="4.1.1 正向传播"></a>4.1.1 正向传播</h4><p>sigmoid函数：                                 </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>ReLU函数：    </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">relu</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
softmax函数：  
 
<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> x<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>T
        x <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> y<span class="token punctuation">.</span>T 

    x <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 溢出对策</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="412-反向传播"><a href="#4-1-2-反向传播" class="headerlink" title="4.1.2 反向传播"></a>4.1.2 反向传播</h4><p>  反向传播本质上是局部求导</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sigmoid_grad</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">relu_grad</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    grad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    grad<span class="token punctuation">[</span>x<span class="token operator">>=</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> grad
</code></pre>
<h4 id="413-损失函数"><a href="#4-1-3-损失函数" class="headerlink" title="4.1.3 损失函数"></a>4.1.3 损失函数</h4><p>损失函数在最后softmax处理后算就可以了</p>
<p>均方误差： </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">mean_squared_error</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#均方差误差</span>
    <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">(</span>y<span class="token operator">-</span>t<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
<p> 交叉熵误差： </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cross_entropy_error</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#交叉熵误差</span>
    <span class="token keyword">if</span> y<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        t <span class="token operator">=</span> t<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> t<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
        y <span class="token operator">=</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
        
    <span class="token comment" spellcheck="true"># 监督数据是one-hot-vector的情况下，转换为正确解标签的索引</span>
    <span class="token keyword">if</span> t<span class="token punctuation">.</span>size <span class="token operator">==</span> y<span class="token punctuation">.</span>size<span class="token punctuation">:</span>
        t <span class="token operator">=</span> t<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
             
    batch_size <span class="token operator">=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token operator">-</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> batch_size

最终损失函数
<span class="token keyword">def</span> <span class="token function">softmax_loss</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#这里选用的是交叉熵误差</span>
    y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token keyword">return</span> cross_entropy_error<span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
</code></pre>
<h3 id="42-layerpy各层的类"><a href="#4-2-layer-py各层的类" class="headerlink" title="4.2 layer.py各层的类"></a>4.2 layer.py各层的类</h3><p>相同结构的层建立一个类，包括各<strong>激活函数</strong>、<strong>Affine</strong>、<strong>卷积池化</strong>、以及<strong>softmax</strong>和<strong>loss</strong></p>
<p>每层包括初始化函数、正向传播、反向传播</p>
<p>​    输入输出均为矩阵形式。正向传播输入输出是参数矩阵，反向输入输出是梯度矩阵</p>
<h4 id="421-relu层"><a href="#4-2-1-ReLU层" class="headerlink" title="4.2.1 ReLU层"></a>4.2.1 ReLU层</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Relu</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>mask <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>mask <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> x<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        out<span class="token punctuation">[</span>self<span class="token punctuation">.</span>mask<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token keyword">return</span> out

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dout<span class="token punctuation">[</span>self<span class="token punctuation">.</span>mask<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
        dx <span class="token operator">=</span> dout

        <span class="token keyword">return</span> dx
</code></pre>
<h4 id="422-sigmoid层"><a href="#4-2-2-sigmoid层" class="headerlink" title="4.2.2 sigmoid层"></a>4.2.2 sigmoid层</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Sigmoid</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        out <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> out
        <span class="token keyword">return</span> out

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dx <span class="token operator">=</span> dout <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>out<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>out

        <span class="token keyword">return</span> dx
</code></pre>
<h4 id="423-affine层全连接层也就是awxb那层"><a href="#4-2-3-Affine层（全连接层，也就是a-wx-b那层）" class="headerlink" title="4.2.3 Affine层（全连接层，也就是a=wx+b那层）"></a>4.2.3 Affine层（全连接层，也就是a=wx+b那层）</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Affine</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span>W
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> b
        
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>original_x_shape <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 权重和偏置参数的导数</span>
        self<span class="token punctuation">.</span>dW <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 对应张量</span>
        self<span class="token punctuation">.</span>original_x_shape <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x

        out <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b

        <span class="token keyword">return</span> out

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dx <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dW <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        
        dx <span class="token operator">=</span> dx<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">*</span>self<span class="token punctuation">.</span>original_x_shape<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 还原输入数据的形状（对应张量）</span>
        <span class="token keyword">return</span> dx
</code></pre>
<h4 id="424-卷积层"><a href="#4-2-4-卷积层" class="headerlink" title="4.2.4 卷积层"></a>4.2.4 卷积层</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Convolution</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> W
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> b
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride
        self<span class="token punctuation">.</span>pad <span class="token operator">=</span> pad
        
        <span class="token comment" spellcheck="true"># 中间数据（backward时使用）</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> None   
        self<span class="token punctuation">.</span>col <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>col_W <span class="token operator">=</span> None
        
        <span class="token comment" spellcheck="true"># 权重和偏置参数的梯度</span>
        self<span class="token punctuation">.</span>dW <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        FN<span class="token punctuation">,</span> C<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>shape
        <span class="token comment" spellcheck="true"># print("输入矩阵初始形状")</span>
        <span class="token comment" spellcheck="true"># print(x.shape)</span>
        N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        out_h <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> int<span class="token punctuation">(</span><span class="token punctuation">(</span>H <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>self<span class="token punctuation">.</span>pad <span class="token operator">-</span> FH<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>
        out_w <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> int<span class="token punctuation">(</span><span class="token punctuation">(</span>W <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>self<span class="token punctuation">.</span>pad <span class="token operator">-</span> FW<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>

        col <span class="token operator">=</span> im2col<span class="token punctuation">(</span>x<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>
        col_W <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>FN<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        <span class="token comment" spellcheck="true"># print("形状")</span>
        <span class="token comment" spellcheck="true"># print(col.shape,col_W.shape)</span>

        out <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>col<span class="token punctuation">,</span> col_W<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> out_h<span class="token punctuation">,</span> out_w<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x
        self<span class="token punctuation">.</span>col <span class="token operator">=</span> col
        self<span class="token punctuation">.</span>col_W <span class="token operator">=</span> col_W

        <span class="token keyword">return</span> out

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        FN<span class="token punctuation">,</span> C<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>shape
        dout <span class="token operator">=</span> dout<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> FN<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>db <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dW <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>col<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dW <span class="token operator">=</span> self<span class="token punctuation">.</span>dW<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>FN<span class="token punctuation">,</span> C<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW<span class="token punctuation">)</span>

        dcol <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> self<span class="token punctuation">.</span>col_W<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        dx <span class="token operator">=</span> col2im<span class="token punctuation">(</span>dcol<span class="token punctuation">,</span> self<span class="token punctuation">.</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> FH<span class="token punctuation">,</span> FW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>

        <span class="token keyword">return</span> dx
</code></pre>
<h4 id="425-池化层"><a href="#4-2-5-池化层" class="headerlink" title="4.2.5 池化层"></a>4.2.5 池化层</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Pooling</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pool_h<span class="token punctuation">,</span> pool_w<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>pool_h <span class="token operator">=</span> pool_h
        self<span class="token punctuation">.</span>pool_w <span class="token operator">=</span> pool_w
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride
        self<span class="token punctuation">.</span>pad <span class="token operator">=</span> pad
        
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>arg_max <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        out_h <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">-</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>
        out_w <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">-</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">)</span>

        col <span class="token operator">=</span> im2col<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>
        col <span class="token operator">=</span> col<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_h<span class="token operator">*</span>self<span class="token punctuation">.</span>pool_w<span class="token punctuation">)</span>

        arg_max <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>col<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>col<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> out_h<span class="token punctuation">,</span> out_w<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x
        self<span class="token punctuation">.</span>arg_max <span class="token operator">=</span> arg_max

        <span class="token keyword">return</span> out

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dout <span class="token operator">=</span> dout<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        
        pool_size <span class="token operator">=</span> self<span class="token punctuation">.</span>pool_h <span class="token operator">*</span> self<span class="token punctuation">.</span>pool_w
        dmax <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>dout<span class="token punctuation">.</span>size<span class="token punctuation">,</span> pool_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        dmax<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>arg_max<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>arg_max<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> dout<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
        dmax <span class="token operator">=</span> dmax<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>dout<span class="token punctuation">.</span>shape <span class="token operator">+</span> <span class="token punctuation">(</span>pool_size<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
        
        dcol <span class="token operator">=</span> dmax<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>dmax<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> dmax<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> dmax<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        dx <span class="token operator">=</span> col2im<span class="token punctuation">(</span>dcol<span class="token punctuation">,</span> self<span class="token punctuation">.</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pad<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> dx
</code></pre>
<h4 id="426-softmax至损失函数层"><a href="#4-2-6-softmax至损失函数层" class="headerlink" title="4.2.6 softmax至损失函数层"></a>4.2.6 softmax至损失函数层</h4><p>将softmax与loss合并为一层</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SoftmaxWithLoss</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>loss <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> None <span class="token comment" spellcheck="true"># softmax的输出</span>
        self<span class="token punctuation">.</span>t <span class="token operator">=</span> None <span class="token comment" spellcheck="true"># 监督数据</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>t <span class="token operator">=</span> t
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>loss <span class="token operator">=</span> cross_entropy_error<span class="token punctuation">(</span>self<span class="token punctuation">.</span>y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>t<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>loss

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dout<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size <span class="token operator">=</span> self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>size <span class="token operator">==</span> self<span class="token punctuation">.</span>y<span class="token punctuation">.</span>size<span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 监督数据是one-hot-vector的情况</span>
            dx <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>y <span class="token operator">-</span> self<span class="token punctuation">.</span>t<span class="token punctuation">)</span> <span class="token operator">/</span> batch_size
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            dx <span class="token operator">=</span> self<span class="token punctuation">.</span>y<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
            dx<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>t<span class="token punctuation">]</span> <span class="token operator">-=</span> <span class="token number">1</span>
            dx <span class="token operator">=</span> dx <span class="token operator">/</span> batch_size
        
        <span class="token keyword">return</span> dx
</code></pre>
<h3 id="43-neuralnet神经网络类"><a href="#4-3-Neuralnet神经网络类" class="headerlink" title="4.3 Neuralnet神经网络类"></a>4.3 Neuralnet神经网络类</h3><p>包括初始化函数（初始化各超参数）、预测函数（神经网络层次递进）、损失函数、准确率函数、梯度函数（学习过程中保存每层各权重的梯度）</p>
<p>  以卷积神经网络为例</p>
<h4 id="431-类变量"><a href="#4-3-1-类变量" class="headerlink" title="4.3.1 类变量"></a>4.3.1 类变量</h4><p>权重参数（字典形式：key-名称；value-矩阵）</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 初始化权重</span>
self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>filter_num<span class="token punctuation">,</span> input_dim<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> filter_size<span class="token punctuation">,</span> filter_size<span class="token punctuation">)</span>
self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>filter_num<span class="token punctuation">)</span>
self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>pool_output_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span>
self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_init_std <span class="token operator">*</span> \
                    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_size<span class="token punctuation">)</span>
</code></pre>
<p>各个层对象（无序表。）</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 生成层</span>
self<span class="token punctuation">.</span>layers <span class="token operator">=</span> OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Convolution<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   conv_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> conv_param<span class="token punctuation">[</span><span class="token string">'pad'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Relu1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Pool1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Pooling<span class="token punctuation">(</span>pool_h<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> pool_w<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Affine<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Relu2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Affine<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

self<span class="token punctuation">.</span>last_layer <span class="token operator">=</span> SoftmaxWithLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="432-初始化函数主要用于定义类变量"><a href="#4-3-2-初始化函数（主要用于定义类变量）" class="headerlink" title="4.3.2 初始化函数（主要用于定义类变量）"></a>4.3.2 初始化函数（主要用于定义类变量）</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
             conv_param<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1&amp;#125;,</span>
             hidden_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> weight_init_std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</code></pre>
<p>包括：</p>
<p>  输入矩阵的形状大小（特征值的数量和排列）</p>
<p>  滤波器的参数（形状、步幅、填充等，滤波器是卷积层的权重）</p>
<p>  各层的神经元数量</p>
<p>  标准差（初始化权重=标准差*范围随机数）</p>
<h4 id="433-预测函数"><a href="#4-3-3-预测函数" class="headerlink" title="4.3.3 预测函数"></a>4.3.3 预测函数</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
<span class="token comment" spellcheck="true">#层次递进，计算到输出层softmax处理前（这里softmax和loss合并了）</span>
    <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    <span class="token keyword">return</span> x
</code></pre>
<h4 id="434-损失函数"><a href="#4-3-4-损失函数" class="headerlink" title="4.3.4 损失函数"></a>4.3.4 损失函数</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""求损失函数
    参数x是输入数据、t是教师标签
       就是比predict多往前走一步（进行softmax处理并求交叉熵误差）
    """</span>
    y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> self<span class="token punctuation">.</span>last_layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>y<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
</code></pre>
<h4 id="435-计算精度"><a href="#4-3-5-计算精度" class="headerlink" title="4.3.5 计算精度"></a>4.3.5 计算精度</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> t<span class="token punctuation">.</span>ndim <span class="token operator">!=</span> <span class="token number">1</span> <span class="token punctuation">:</span> t <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>t<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    
    acc <span class="token operator">=</span> <span class="token number">0.0</span>
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>int<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        tx <span class="token operator">=</span> x<span class="token punctuation">[</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>batch_size<span class="token punctuation">]</span>
        tt <span class="token operator">=</span> t<span class="token punctuation">[</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>batch_size<span class="token punctuation">]</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>tx<span class="token punctuation">)</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        acc <span class="token operator">+=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>y <span class="token operator">==</span> tt<span class="token punctuation">)</span> 
    
    <span class="token keyword">return</span> acc <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre>
<h4 id="436-求梯度"><a href="#4-3-6-求梯度" class="headerlink" title="4.3.6 求梯度"></a>4.3.6 求梯度</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">gradient</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""求梯度（误差反向传播法）
    Parameters
    ----------
    x : 输入数据
    t : 标签值
    Returns
    -------
    具有各层的梯度的字典变量
        grads['W1']、grads['W2']、...是各层的权重
        grads['b1']、grads['b2']、...是各层的偏置
    """</span>
    <span class="token comment" spellcheck="true"># forward</span>
    self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># backward</span>
    dout <span class="token operator">=</span> <span class="token number">1</span>
    dout <span class="token operator">=</span> self<span class="token punctuation">.</span>last_layer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>dout<span class="token punctuation">)</span>

    layers <span class="token operator">=</span> list<span class="token punctuation">(</span>self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    layers<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
        dout <span class="token operator">=</span> layer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>dout<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 设定</span>
    grads <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db
    grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine1'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db
    grads<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token string">'Affine2'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>db

    <span class="token keyword">return</span> grads
</code></pre>
<h4 id="437-保存参数学习完后保存下最终权重等参数"><a href="#4-3-7-保存参数（学习完后保存下最终权重等参数）" class="headerlink" title="4.3.7 保存参数（学习完后保存下最终权重等参数）"></a>4.3.7 保存参数（学习完后保存下最终权重等参数）</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">save_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_name<span class="token operator">=</span><span class="token string">"params.pkl"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    params <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> val
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>params<span class="token punctuation">,</span> f<span class="token punctuation">)</span>
</code></pre>
<h4 id="438-加载参数预测时加载之前学习到的参数"><a href="#4-3-8-加载参数（预测时加载之前学习到的参数）" class="headerlink" title="4.3.8 加载参数（预测时加载之前学习到的参数）"></a>4.3.8 加载参数（预测时加载之前学习到的参数）</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_name<span class="token operator">=</span><span class="token string">"params.pkl"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        params <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> val

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> key <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Conv1'</span><span class="token punctuation">,</span> <span class="token string">'Affine1'</span><span class="token punctuation">,</span> <span class="token string">'Affine2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>W <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>b <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre>
<h3 id="44-trainer训练类学习类"><a href="#4-4-Trainer训练类（学习类）" class="headerlink" title="4.4 Trainer训练类（学习类）"></a>4.4 Trainer训练类（学习类）</h3><p>  包括初始化函数（确认训练测试集以及其他训练所用参数等）、训练函数等</p>
<h4 id="441-类变量及初始化函数"><a href="#4-4-1-类变量及初始化函数" class="headerlink" title="4.4.1 类变量及初始化函数"></a>4.4.1 类变量及初始化函数</h4><p>初始化：<br>   训练所用的 训练测试集、分片、epoch、参数更新算法、神经网络、训练次数</p>
<p>初始化函数：主要用于定义、初始化变量</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> network<span class="token punctuation">,</span> x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">,</span>
             epochs<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> mini_batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
             optimizer<span class="token operator">=</span><span class="token string">'SGD'</span><span class="token punctuation">,</span> optimizer_param<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'lr':0.01&amp;#125;, </span>
             evaluate_sample_num_per_epoch<span class="token operator">=</span>None<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>network <span class="token operator">=</span> network<span class="token comment" spellcheck="true">#神经网络（type=神经网络类）</span>
    self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> verbose<span class="token comment" spellcheck="true">#是否实时输出迭代信息</span>
    self<span class="token punctuation">.</span>x_train <span class="token operator">=</span> x_train<span class="token comment" spellcheck="true">#训练样本数据集（type=np.array）</span>
    self<span class="token punctuation">.</span>t_train <span class="token operator">=</span> t_train<span class="token comment" spellcheck="true">#训练监督数据集</span>
    self<span class="token punctuation">.</span>x_test <span class="token operator">=</span> x_test<span class="token comment" spellcheck="true">#测试样本数据集</span>
    self<span class="token punctuation">.</span>t_test <span class="token operator">=</span> t_test<span class="token comment" spellcheck="true">#测试监督数据集</span>
    self<span class="token punctuation">.</span>epochs <span class="token operator">=</span> epochs<span class="token comment" spellcheck="true">#epoch的数量。epoch，把所有样本都过一遍的分片循环次数</span>
    self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> mini_batch_size<span class="token comment" spellcheck="true">#分片大小</span>
    self<span class="token punctuation">.</span>evaluate_sample_num_per_epoch<span class="token comment" spellcheck="true">#每个epoch有几个样本数，默认None，也就是所有样本/epoch</span>
<span class="token comment" spellcheck="true"># optimzer：优化器（优化算法，更新权重等参数的算法）</span>
optimizer_class_dict <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'sgd':SGD, 'momentum':Momentum, 'nesterov':Nesterov, 'adagrad':AdaGrad, 'rmsprpo':RMSprop, 'adam':Adam&amp;#125;</span>
    
self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span>   
optimizer_class_dict<span class="token punctuation">[</span>optimizer<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token operator">**</span>optimizer_param<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#SGD(&amp;#123;'lr':0.01&amp;#125;),**表示参数以字典形式导入</span>
    self<span class="token punctuation">.</span>train_size <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#训练数据集大小</span>
    self<span class="token punctuation">.</span>iter_per_epoch <span class="token operator">=</span> max<span class="token punctuation">(</span>self<span class="token punctuation">.</span>train_size <span class="token operator">/</span> mini_batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#1个epoch的大小，把所有样本都过一遍的分片循环次数</span>
    self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> int<span class="token punctuation">(</span>epochs <span class="token operator">*</span> self<span class="token punctuation">.</span>iter_per_epoch<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#迭代次数（训练次数，以学习一个分片为一次）</span>
 
</code></pre>
<p>训练中：<br>   实时保存 当前训练次数、当前精度、当前损失函数</p>
<pre class=" language-python"><code class="language-python">    self<span class="token punctuation">.</span>current_iter <span class="token operator">=</span> <span class="token number">0</span><span class="token comment" spellcheck="true">#当前迭代次数</span>
    self<span class="token punctuation">.</span>current_epoch <span class="token operator">=</span> <span class="token number">0</span><span class="token comment" spellcheck="true">#当前epoch数</span>
    <span class="token comment" spellcheck="true">#记录下迭代信息，方便画图（以epoch为单位）</span>
    self<span class="token punctuation">.</span>train_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#损失函数</span>
    self<span class="token punctuation">.</span>train_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#训练准确率</span>
    self<span class="token punctuation">.</span>test_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#测试准确率</span>
</code></pre>
<h4 id="442-训练函数"><a href="#4-4-2-训练函数" class="headerlink" title="4.4.2 训练函数"></a>4.4.2 训练函数</h4><p>（每个分片）训练学习的函数，其中包括<br>   分片、计算梯度、按梯度更新权重、计算保存损失函数、计算保存训练测试精度等</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_step</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    （每个分片）训练学习的函数，其中包括
        分片、计算梯度、按梯度更新权重、计算保存损失函数、计算保存训练测试精度等
    Returns
    -------
    """</span>
    batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>self<span class="token punctuation">.</span>train_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#从[0,train_size)中随机选取batch_size个数字</span>
    x_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>x_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#分片大小&lt;=batch_size，因为batch_mask中有重复元素</span>
    t_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>t_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true">#神经网络类的gradient函数封装了实时保存权重梯度的功能</span>
    grads <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>update<span class="token punctuation">(</span>self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>params<span class="token punctuation">,</span> grads<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#按照梯度更新权重</span>

    <span class="token comment" spellcheck="true">#计算保存损失函数</span>
    loss <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>x_batch<span class="token punctuation">,</span> t_batch<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>train_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train loss:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>current_iter <span class="token operator">%</span> self<span class="token punctuation">.</span>iter_per_epoch <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>current_epoch <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token comment" spellcheck="true">#一次epoch结束保存训练测试精度</span>
        x_train_sample<span class="token punctuation">,</span> t_train_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>x_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_train
        x_test_sample<span class="token punctuation">,</span> t_test_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>x_test<span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_test

        <span class="token comment" spellcheck="true"># 指定epoch大小的情况下，一般不指定，默认全部样本为一个epoch</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>evaluate_sample_num_per_epoch <span class="token keyword">is</span> None<span class="token punctuation">:</span>
            t <span class="token operator">=</span> self<span class="token punctuation">.</span>evaluate_sample_num_per_epoch
            x_train_sample<span class="token punctuation">,</span> t_train_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>x_train<span class="token punctuation">[</span><span class="token punctuation">:</span>t<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_train<span class="token punctuation">[</span><span class="token punctuation">:</span>t<span class="token punctuation">]</span>
            x_test_sample<span class="token punctuation">,</span> t_test_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>x_test<span class="token punctuation">[</span><span class="token punctuation">:</span>t<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_test<span class="token punctuation">[</span><span class="token punctuation">:</span>t<span class="token punctuation">]</span>
            
        train_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_train_sample<span class="token punctuation">,</span> t_train_sample<span class="token punctuation">)</span>
        test_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>x_test_sample<span class="token punctuation">,</span> t_test_sample<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>train_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>test_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=== epoch:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>self<span class="token punctuation">.</span>current_epoch<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">", train acc:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">", test acc:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" ==="</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>current_iter <span class="token operator">+=</span> <span class="token number">1</span>
</code></pre>
<h4 id="443-最终训练函数提供给外界的api"><a href="#4-4-3-最终训练函数（提供给外界的API）" class="headerlink" title="4.4.3 最终训练函数（提供给外界的API）"></a>4.4.3 最终训练函数（提供给外界的API）</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    总训练，
    Returns
    -------
    """</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>train_step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true">#最终精度，用学习完的权重参数最后预测一次测试数据集</span>
    test_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x_test<span class="token punctuation">,</span> self<span class="token punctuation">.</span>t_test<span class="token punctuation">)</span>

    <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=============== Final Test Accuracy ==============="</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"test acc:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>test_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="45-数据集加载mnistpy"><a href="#4-5-数据集加载mnist-py" class="headerlink" title="4.5 数据集加载mnist.py"></a>4.5 数据集加载mnist.py</h3><h4 id="451-初始化所需参数"><a href="#4-5-1-初始化所需参数" class="headerlink" title="4.5.1 初始化所需参数"></a>4.5.1 初始化所需参数</h4><ol>
<li><p>爬数据的网站url</p>
</li>
<li><p>本地保存路径（网上下载的压缩文件）</p>
</li>
<li><p>本地保存路径（用于实验的处理后数据）</p>
</li>
<li><p>训练/测试次数</p>
</li>
<li><p>图片像素/一维展开后大小</p>
</li>
</ol>
<pre class=" language-python"><code class="language-python">url_base <span class="token operator">=</span> <span class="token string">'http://yann.lecun.com/exdb/mnist/'</span>
key_file <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
    <span class="token string">'train_img'</span><span class="token punctuation">:</span><span class="token string">'train-images-idx3-ubyte.gz'</span><span class="token punctuation">,</span>
    <span class="token string">'train_label'</span><span class="token punctuation">:</span><span class="token string">'train-labels-idx1-ubyte.gz'</span><span class="token punctuation">,</span>
    <span class="token string">'test_img'</span><span class="token punctuation">:</span><span class="token string">'t10k-images-idx3-ubyte.gz'</span><span class="token punctuation">,</span>
    <span class="token string">'test_label'</span><span class="token punctuation">:</span><span class="token string">'t10k-labels-idx1-ubyte.gz'</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>
<span class="token comment" spellcheck="true">#父目录路径</span>
dataset_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span>
save_file <span class="token operator">=</span> dataset_dir <span class="token operator">+</span> <span class="token string">"/mnist.pkl"</span>

train_num <span class="token operator">=</span> <span class="token number">60000</span>
test_num <span class="token operator">=</span> <span class="token number">10000</span>
img_dim <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
img_size <span class="token operator">=</span> <span class="token number">784</span>
</code></pre>
<h4 id="452-下载所需数据集"><a href="#4-5-2-下载所需数据集" class="headerlink" title="4.5.2 下载所需数据集"></a>4.5.2 下载所需数据集</h4><ol>
<li>作用：从网站上按照url+file_name爬数据，每个文件爬一次即可（第一次执行会有点慢，之后都正常）</li>
<li>下载下来的数据一般需要后序处理（解压缩等）</li>
</ol>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_download</span><span class="token punctuation">(</span>file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>

    file_path <span class="token operator">=</span> dataset_dir <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> file_name
    
    <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Downloading "</span> <span class="token operator">+</span> file_name <span class="token operator">+</span> <span class="token string">" ... "</span><span class="token punctuation">)</span>
 
    <span class="token comment" spellcheck="true"># 把url_base+file_name的数据下载到本地file_path</span>
    urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlretrieve<span class="token punctuation">(</span>url_base <span class="token operator">+</span> file_name<span class="token punctuation">,</span> file_path<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done"</span><span class="token punctuation">)</span>
    
<span class="token keyword">def</span> <span class="token function">download_mnist</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    将mnist数据集中需要用到的数据（上面key_file字典中定义的）下载下来
    Returns
    -------

    """</span>
    <span class="token keyword">for</span> v <span class="token keyword">in</span> key_file<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
       _download<span class="token punctuation">(</span>v<span class="token punctuation">)</span>
</code></pre>
<h4 id="453-解压打开gzip文件"><a href="#4-5-3-解压打开gzip文件" class="headerlink" title="4.5.3 解压打开gzip文件"></a>4.5.3 解压打开gzip文件</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_load_label</span><span class="token punctuation">(</span>file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""读取gzip文件并提示，读取成功打印Done
    Returns 文件内容(多维向量)
    """</span>
    file_path <span class="token operator">=</span> dataset_dir <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> file_name
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Converting "</span> <span class="token operator">+</span> file_name <span class="token operator">+</span> <span class="token string">" to NumPy Array ..."</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> gzip<span class="token punctuation">.</span>open<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#打开gzip文件，rb r-只读，b-读取的是二进制文件</span>
            labels <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>uint8<span class="token punctuation">,</span> offset<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># numpy.frombuffer(buffer, dtype=float, count=-1, offset=0)</span>
        <span class="token comment" spellcheck="true"># 参数</span>
        <span class="token comment" spellcheck="true">#     缓冲区：它表示暴露缓冲区接口的对象。</span>
        <span class="token comment" spellcheck="true">#     dtype：代表返回的数据类型数组的数据类型。</span>
        <span class="token comment" spellcheck="true">#     count：代表返回的ndarray的长度。默认值为-1。</span>
        <span class="token comment" spellcheck="true">#     偏移量：代表读取的起始位置。默认值为0。</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done"</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> labels

<span class="token keyword">def</span> <span class="token function">_load_img</span><span class="token punctuation">(</span>file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    打开图像数据的gzip文件并转换成1*784的一维向量
    Parameters
    ----------
    file_name

    Returns 一维展开的输入图像数据（一维向量）
    -------

    """</span>
    file_path <span class="token operator">=</span> dataset_dir <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> file_name
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Converting "</span> <span class="token operator">+</span> file_name <span class="token operator">+</span> <span class="token string">" to NumPy Array ..."</span><span class="token punctuation">)</span>    
    <span class="token keyword">with</span> gzip<span class="token punctuation">.</span>open<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            data <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>uint8<span class="token punctuation">,</span> offset<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> img_size<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done"</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> data
</code></pre>
<h4 id="454-将数据集信息保存在dict中"><a href="#4-5-4-将数据集信息保存在dict中" class="headerlink" title="4.5.4 将数据集信息保存在dict中"></a>4.5.4 将数据集信息保存在dict中</h4><ol>
<li>主要方便于init_mnist()中将数据集保存在本地文件中</li>
</ol>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_convert_numpy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Returns 以字典dict形式返回训练集/测试集
    key-描述数据集监督数据/测试数据 的字符串
    value-监督数据（label）/测试数据（image）的numpy表示
    -------

    """</span>
    dataset <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
    dataset<span class="token punctuation">[</span><span class="token string">'train_img'</span><span class="token punctuation">]</span> <span class="token operator">=</span>  _load_img<span class="token punctuation">(</span>key_file<span class="token punctuation">[</span><span class="token string">'train_img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    dataset<span class="token punctuation">[</span><span class="token string">'train_label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> _load_label<span class="token punctuation">(</span>key_file<span class="token punctuation">[</span><span class="token string">'train_label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    
    dataset<span class="token punctuation">[</span><span class="token string">'test_img'</span><span class="token punctuation">]</span> <span class="token operator">=</span> _load_img<span class="token punctuation">(</span>key_file<span class="token punctuation">[</span><span class="token string">'test_img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    dataset<span class="token punctuation">[</span><span class="token string">'test_label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> _load_label<span class="token punctuation">(</span>key_file<span class="token punctuation">[</span><span class="token string">'test_label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> dataset
</code></pre>
<h4 id="455-将解压后的数据集保存到本地"><a href="#4-5-5-将解压后的数据集保存到本地" class="headerlink" title="4.5.5 将解压后的数据集保存到本地"></a>4.5.5 将解压后的数据集保存到本地</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">init_mnist</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    将下载下来的数据保存到本地文件中save_file中
    Returns
    -------

    """</span>
    download_mnist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    dataset <span class="token operator">=</span> _convert_numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Creating pickle file ..."</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>save_file<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#wb-写入二进制文件</span>
        pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> f<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将dataset的数据保存到f中，本例是save_file文件，即mnist.pkl。-1表示使用最高protocol对dataset压缩</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="456-监督数据格式转换"><a href="#4-5-6-监督数据格式转换" class="headerlink" title="4.5.6 监督数据格式转换"></a>4.5.6 监督数据格式转换</h4><ol>
<li>如果参数one_hot_label=False就不用执行此函数</li>
</ol>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_change_one_hot_label</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    将监督数据转换成[0,0,1,0,0,0,0,0,0,0]的形式
    Parameters
    ----------
    X 一组监督数据。如[5,9,8,3,4,6]。一维向量

    Returns 一维向量形式的监督数据（一组）
    -------

    """</span>
    T <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>size<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#10是因为本例数字识别一共10个数</span>
    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> row <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#枚举，同时遍历索引和元素</span>
        <span class="token comment" spellcheck="true">#idx-索引，row-（idx索引指向的）元素</span>
        <span class="token comment" spellcheck="true">#row是一个监督数据（标签），T是一组</span>
        row<span class="token punctuation">[</span>X<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        
    <span class="token keyword">return</span> T
</code></pre>
<h4 id="457-对外接口api"><a href="#4-5-7-对外接口api" class="headerlink" title="4.5.7 对外接口api"></a>4.5.7 对外接口api</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_mnist</span><span class="token punctuation">(</span>normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> flatten<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> one_hot_label<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""读入MNIST数据集
    
    Parameters
    ----------
    normalize : 将图像的像素值正规化为0.0~1.0
    one_hot_label : 
        one_hot_label为True的情况下，标签作为one-hot数组返回
        one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组
    flatten : 是否将图像展开为一维数组
    
    Returns
    -------
    (训练图像, 训练标签), (测试图像, 测试标签)
    """</span>
    <span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
        init_mnist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>save_file<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        dataset <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#加载本地下载好的数据集</span>
    
    <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>
        <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'train_img'</span><span class="token punctuation">,</span> <span class="token string">'test_img'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dataset<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> dataset<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#转换成固定的数据类型float32</span>
            dataset<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">/=</span> <span class="token number">255.0</span>
            
    <span class="token keyword">if</span> one_hot_label<span class="token punctuation">:</span>
        dataset<span class="token punctuation">[</span><span class="token string">'train_label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> _change_one_hot_label<span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">'train_label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        dataset<span class="token punctuation">[</span><span class="token string">'test_label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> _change_one_hot_label<span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">'test_label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> <span class="token operator">not</span> flatten<span class="token punctuation">:</span>
         <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'train_img'</span><span class="token punctuation">,</span> <span class="token string">'test_img'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dataset<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> dataset<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">'train_img'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dataset<span class="token punctuation">[</span><span class="token string">'train_label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">'test_img'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dataset<span class="token punctuation">[</span><span class="token string">'test_label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
</code></pre>
<h3 id="46-执行主函数包括图像显示"><a href="#4-6-执行主函数（包括图像显示）" class="headerlink" title="4.6 执行主函数（包括图像显示）"></a>4.6 执行主函数（包括图像显示）</h3><h4 id="461-读入数据"><a href="#4-6-1-读入数据" class="headerlink" title="4.6.1 读入数据"></a>4.6.1 读入数据</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 读入数据</span>
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">)</span> <span class="token operator">=</span> load_mnist<span class="token punctuation">(</span>flatten<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 处理花费时间较长的情况下减少数据 取前5000个样本</span>
<span class="token comment" spellcheck="true">#x_train, t_train = x_train[:5000], t_train[:5000]</span>
<span class="token comment" spellcheck="true">#x_test, t_test = x_test[:1000], t_test[:1000]</span>

max_epochs <span class="token operator">=</span> <span class="token number">20</span><span class="token comment" spellcheck="true">#20轮次</span>
</code></pre>
<h4 id="462-创建神经网络对象"><a href="#4-6-2-创建神经网络对象" class="headerlink" title="4.6.2 创建神经网络对象"></a>4.6.2 创建神经网络对象</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#建立神经网络</span>
network <span class="token operator">=</span> SimpleConvNet<span class="token punctuation">(</span>input_dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                        conv_param <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1&amp;#125;,</span>
                        hidden_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> weight_init_std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="463-创建训练对象"><a href="#4-6-3-创建训练对象" class="headerlink" title="4.6.3 创建训练对象"></a>4.6.3 创建训练对象</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#训练对象，拟定训练参数</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>network<span class="token punctuation">,</span> x_train<span class="token punctuation">,</span> t_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> t_test<span class="token punctuation">,</span>
                  epochs<span class="token operator">=</span>max_epochs<span class="token punctuation">,</span> mini_batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
                  optimizer<span class="token operator">=</span><span class="token string">'Adam'</span><span class="token punctuation">,</span> optimizer_param<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'lr': 0.001&amp;#125;,</span>
                  evaluate_sample_num_per_epoch<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="464-训练并保存参数"><a href="#4-6-4-训练并保存参数" class="headerlink" title="4.6.4 训练并保存参数"></a>4.6.4 训练并保存参数</h4><pre class=" language-python"><code class="language-python">trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 保存参数</span>
network<span class="token punctuation">.</span>save_params<span class="token punctuation">(</span><span class="token string">"params.pkl"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Saved Network Parameters!"</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="465-绘图"><a href="#4-6-5-绘图" class="headerlink" title="4.6.5 绘图"></a>4.6.5 绘图</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 绘制图形</span>
markers <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'train': 'o', 'test': 's'&amp;#125;</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>max_epochs<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> trainer<span class="token punctuation">.</span>train_acc_list<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> markevery<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> trainer<span class="token punctuation">.</span>test_acc_list<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'s'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span> markevery<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"epochs"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><ol>
<li><p><strong>初始化：</strong>选取初始权重<code>ω</code>和偏置<code>b</code>。<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM5Nzg5NzcvYXJ0aWNsZS9kZXRhaWxzLzg0ODYxNDUz">参数初始化方法</span></p>
<ol>
<li>包括<code>reset_parameters</code>、<code>.uniform_</code>等都是相关<strong>初始化</strong>方法</li>
<li><code>torch.empty()</code>、<code>torch.rand()</code>、<code>torch.Tensor()</code>：随机生成<strong>张量</strong>的方法</li>
</ol>
</li>
<li><p><strong>建立模型：</strong>即神经网络模型。模型包扩但不限于<strong>参数（权重、偏置、梯度…）</strong>、<strong>每层的对象（也算模型）</strong>，神经网络是由多个函数模型组合而成的模型。</p>
<ol>
<li><code>liner()</code>：线性模型，回归层用到比较多（如果有的话）</li>
<li><code>LSTMCell()</code>：RNN的memory层</li>
</ol>
</li>
<li><p><strong>预测：</strong>根据模型参数求预测值</p>
<ol>
<li><code>forward()</code>：根据<strong>公式</strong>，将<strong>各层</strong>输入转为输出，在下一层输入。</li>
<li><code>predict()</code>：主要工作是根据<strong>学习模型</strong>，将<strong>输入</strong>转换成<strong>输出</strong>。是<code>forward</code>的集成</li>
</ol>
</li>
<li><p><strong>损失函数</strong>：计算预测值和标签值的误差，用于<strong>更新</strong>模型参数</p>
<ol>
<li><code>loss()</code>：损失函数一般都命名为loss，主要分<strong>均方差</strong>和<strong>交叉熵</strong>2种方法</li>
<li><code>mean_squared_error()</code>：均方误差</li>
<li><code>cross_entropy_error()</code>：交叉熵误差</li>
<li><code>binary_cross_entropy_error()</code>：二元交叉熵</li>
<li><code>binary_cross_entropy_error_with_logits()</code>：集成sigmod的二元交叉熵</li>
</ol>
</li>
<li><p><strong>求梯度：</strong>主要是求关于<strong>权重</strong>的梯度。一般用求导公式或<strong>误差反向传播算法</strong></p>
<ol>
<li><code>backward()</code>：可以说是<code>forward()</code>的反函数，根据各层上游的<strong>梯度</strong>及该层公式，计算出此层的<strong>梯度</strong></li>
<li><code>gradient()</code>：求出<strong>每一层</strong>的梯度，集成了<code>backward()</code></li>
</ol>
</li>
<li><p><strong>更新权重：</strong>向损失函数<strong>梯度反方向</strong>更新参数。(参数包括各层<strong>权重</strong>、<strong>偏置</strong>、<strong>梯度</strong>等)</p>
<ol>
<li><p><code>params -= learning_rate * grad</code>：根据<strong>学习率</strong>和<strong>梯度</strong>反向更新即可，这是常规写法</p>
</li>
<li><p><code>torch</code>更新：</p>
<ol>
<li><p>新建一个优化器，参数内容：学习率、模型的所有参数（权重、梯度等）</p>
<pre class=" language-python"><code class="language-python">optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#此例是SGD优化器，lr：学习率</span>
optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#Adam优化器</span>
</code></pre>
</li>
<li><p>通过优化器更新参数</p>
<pre class=" language-python"><code class="language-python">optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#gradient descent</span>
</code></pre>
</li>
</ol>
</li>
</ol>
</li>
<li><p><strong>预测：</strong>是否满足要求？是→结束；否→继续3,4,5</p>
</li>
</ol>
<h1 id="六-支持向量机"><a href="#六、-支持向量机" class="headerlink" title="六、 支持向量机"></a>六、 支持向量机</h1><p>什么是支持向量机(SVM)：<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzIxMDk0NDg5JUUzJTgwJTgyJUU1JThGJUFGJUU0JUJCJUE1JUU3JTlDJThCJUU3JTlDJThCJUU4JUJGJTk5JUU0JUI4JUFBJUVGJUJDJThDJUU4JUFFJUIyJUU1JUJFJTk3JUU5JTlEJTlFJUU1JUI4JUI4JUU5JTgwJTlBJUU0JUJGJTk3JUU2JTk4JTkzJUU2JTg3JTgy">https://www.zhihu.com/question/21094489。可以看看这个，讲得非常通俗易懂</span></p>
<blockquote>
<p>大意是找个<strong>函数</strong>尽可能把2类东西分开。</p>
</blockquote>
<p>一维：<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/7befaafc45763b9c4469abf245dc98cb_720w.jpg" alt="img">二维：<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/55d7ad2a6e23579b17aec0c3c9135eb3_720w.jpg" alt="img"></p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><blockquote>
<ul>
<li><p><strong>正则化是为了防止过拟合</strong></p>
</li>
<li><p>理论上来讲正则起到的作用就是：“损失精度去调整样本的不足产生的拟合”。</p>
</li>
</ul>
</blockquote>
<p>正则化的英文 Regularizaiton-Regular-Regularize，<strong>直译应该是：规则化</strong></p>
<h1 id="十-knn算法"><a href="#十、-KNN算法" class="headerlink" title="十、 KNN算法"></a>十、 KNN算法</h1><p>参考：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMzkwOTY1NjA=">https://zhuanlan.zhihu.com/p/339096560</span></p>
<h2 id="1-knn算法"><a href="#1-KNN算法" class="headerlink" title="1. KNN算法"></a>1. KNN算法</h2><blockquote>
<p>所谓K最近邻，就是K个最近的邻居的意思，说的是每个样本都可以用它最接近的K个邻近值来代表。</p>
</blockquote>
<ul>
<li>优：简单</li>
<li>缺：计算量大，对每一个待分类的文本都要计算它到全体已知样本的距离。<ul>
<li>剪辑：事先去除对分类作用不大的样本</li>
</ul>
</li>
</ul>
<h3 id="11-步骤"><a href="#1-1-步骤" class="headerlink" title="1.1 步骤"></a>1.1 步骤</h3><ol>
<li><p><strong>距离</strong>度量：常用<strong>欧几里得距离</strong>。<br>$$<br>\sqrt[p]{\sum_{i}\left | x_{1}-x_{2} \right |^{p}}<br>$$</p>
<ol>
<li>当p=1时，就是曼哈顿距离（对应<code>L1</code>范数）</li>
<li>当p=2时，就是欧氏距离（对应L2范数）</li>
<li>当p→∞时，就是切比雪夫距离</li>
</ol>
</li>
<li><p><strong>K值</strong>选择：距离最近的K个样本。通常采用<strong>交叉验证法</strong>来选取最优的K值。</p>
<ul>
<li>K值较小：训练误差↓，测试误差↑。<strong>容易过拟合</strong></li>
<li>K值较大：训练误差↑，测试误差↓。<strong>容易训练不到位</strong></li>
</ul>
</li>
</ol>
<h3 id="12-代码实现"><a href="#1-2-代码实现" class="headerlink" title="1.2 代码实现"></a>1.2 代码实现</h3><p>knn的库为<code>KNeighborsRegressor</code></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsRegressor
</code></pre>
<p><strong>生成训练数据</strong>：以sin函数测试</p>
<pre class=" language-python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 随机生成40个(0, 1)之前的数，乘以5，再进行升序</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token number">5</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 使用sin函数得到y值，并拉伸到一维</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># y值增加噪声</span>
y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">0.5</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#在图像上显示样本点，s是点的大小，label表示样本标签，一般显示在图像右上角</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'bad'</span><span class="token punctuation">)</span> 
</code></pre>
<p>显示如下：</p>
<p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/1654135.png" alt="img"></p>
<p><strong>KNN学习-预测</strong></p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#建立模型，k近邻数=3，L2欧几里得距离</span>
clf <span class="token operator">=</span> KNeighborsRegressor<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 拟合</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 预测</span>
<span class="token comment" spellcheck="true"># 创建[0, 5]之间的500个数的等差数列, 作为测试数据</span>
T <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#y_是预测值，y_real是数据的实际值</span>
y_ <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>T<span class="token punctuation">)</span>
y_real<span class="token operator">=</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>T<span class="token punctuation">,</span>y_real<span class="token punctuation">,</span>marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'bad'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#在图像上显示样本点，s是点的大小，label表示样本标签，一般显示在图像右上角</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>T<span class="token punctuation">,</span> y_<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#根据X,Y画出描点图，其实主要作用是连线。X_pred和Y_pred一般为数组</span>
</code></pre>
<p>如下图：</p>
<p> <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/156465.png" alt="img"></p>
<p><strong>关于sklearn.neighbors.KNeighborsRegressor</strong></p>
<p>KNN的模型应该是一张<strong>距离表</strong></p>
<pre class=" language-python"><code class="language-python">KNeighborsRegressor<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token operator">*</span><span class="token punctuation">,</span> weights<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">,</span> algorithm<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> leaf_size<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token string">'minkowski'</span><span class="token punctuation">,</span> metric_params<span class="token operator">=</span>None<span class="token punctuation">,</span> n_jobs<span class="token operator">=</span>None<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    <span class="token triple-quoted-string string">"""
    最近邻回归，用于预测连续数值
    :param n_neighbors: int, default=5。k值，最近的k个邻居
    :param weights: 
    :param algorithm: 寻找最近邻的算法
        ball_tree：will use BallTree。
        kd_tree： will use KDTree
        brute： 暴力穷举
        auto： 自动选择
    :param leaf_size: int, default=30。传递给BallTree或KDTree的叶大小。这会影响构造和查询的速度，以及存储树所需的内存。
    :param p: int, default=2。当p=1时，使用曼哈顿距离（l1）；对p=2时，欧几里德距离（l2）。对于任意p，使用minkowski距离（lp）。
    :param metric: str or callable, default=’minkowski’。要用于树的距离度量。默认的度量是minkowski，p=2等于标准的欧几里德度量。有关可用度量的列表
    :param metric_params: 
    :param n_jobs: int, default=None。为邻居搜索运行的并行作业数。
    :param kwargs: 
    :return: KNN模型
    """</span>
</code></pre>
<blockquote>
<p>一般指定一个k就可以了</p>
</blockquote>
<pre class=" language-python"><code class="language-python">neigh <span class="token operator">=</span> KNeighborsRegressor<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
<p><strong>此外，关于近邻的遍历算法：</strong></p>
<ul>
<li><strong>KDTree：</strong>对于<strong>低维度</strong> (<img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/7fb5b8aaa79d55e35332a1f02a5aee04.jpg" alt="D &lt; 20">) 近邻搜索非常快, 当 <img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/e03066df748abd9273db055cb79f0f01.jpg" alt="D"> 增长到很大时, 效率变低。这就是所谓的 “维度灾难” 的一种体现。</li>
<li><strong>BallTree：</strong>比 KD 树消耗更多的时间, 但是这种数据结构对于高结构化的数据是非常有效的, 即使在<strong>高维度</strong>上也是一样.</li>
</ul>
<p>函数<code>KNeighborsRegressor()</code>返回一个<code>KNeighborsRegressor</code>对象。</p>
<p><strong>常用属性（成员变量）：</strong></p>
<ul>
<li><code>effective_metric_</code>：<strong>str or callable</strong>。距离度量。如<code>metric=&#39;minkowski&#39;</code>并且<code>p=2</code>时，返回<code>euclidean-欧几里得</code></li>
<li><code>effective_metric_params_</code>：<strong>dict</strong>。度量函数的其他参数</li>
<li><code>n_samples_fit_</code>：<strong>int</strong>。用于训练的样本数</li>
</ul>
<p><strong>常用函数：</strong></p>
<ul>
<li><p><code>fit(X, y)</code>：拟合（训练）模型。</p>
</li>
<li><p><code>predict(X)</code>：预测</p>
</li>
<li><p><code>get_params(deep=True)</code>：以字典形式返回模型参数，包括但不限于<code>fit_intercept</code></p>
</li>
<li><p><code>set_params(**params)</code>：设置参数</p>
</li>
<li><p><code>kneighbors(X=None, n_neighbors=None, return_distance=True)</code>：返回指定样本的最近的k个邻居</p>
<ul>
<li><code>X</code>：<strong>array</strong>。样本数组</li>
<li><code>n_neighbors</code>：<strong>int</strong>。邻居数，默认是一开始传入的k值</li>
<li><code>return_distance</code>：<strong>bool</strong>。是否返回距离。</li>
<li><strong>return</strong>：<ul>
<li><code>neigh_dist</code>：<strong>ndarray</strong>。各邻居的距离（需要return_distance为true）。二维数组（一维-样本；二维-每个样本的邻居们）</li>
<li><code>neigh_ind </code>：<strong>ndarray</strong>。邻居的索引。二维数组（一维-样本；二维-每个样本的邻居们）</li>
</ul>
</li>
</ul>
<p>例：</p>
<pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> samples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">>></span><span class="token operator">></span> neigh <span class="token operator">=</span> NearestNeighbors<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#NearestNeighbors是无监督的最近邻</span>
<span class="token operator">>></span><span class="token operator">></span> neigh<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>samples<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> neigh<span class="token punctuation">.</span>kneighbors<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#表示最近的1个邻居距离为0.5，index=2</span>
<span class="token comment" spellcheck="true">#或者这样接收也可</span>
distances<span class="token punctuation">,</span> indices <span class="token operator">=</span> neigh<span class="token punctuation">.</span>kneighbors<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> distances
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#行-样本，列-样本的每个邻居的距离</span>
<span class="token operator">>></span><span class="token operator">></span> indices
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#最近的1个邻居是index=2的点</span>
</code></pre>
</li>
<li><p><code>kneighbors_graph(X=None, n_neighbors=None,mode=&#39;connectivity&#39;)</code>：返回邻居<strong>连接图</strong>，1-相邻；0-不相邻</p>
<ul>
<li><code>X</code>：<strong>array</strong>。样本数组</li>
<li><code>n_neighbors</code>：<strong>int</strong>。邻居数，默认是一开始传入的k值</li>
<li><code>mode</code>：返回矩阵的类型</li>
<li><strong>return</strong>：返回一个距离矩阵，可通过<code>toArray()</code>转为<strong>array</strong>。</li>
</ul>
<p>例：</p>
<pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">>></span><span class="token operator">></span> neigh <span class="token operator">=</span> NearestNeighbors<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> A <span class="token operator">=</span> neigh<span class="token punctuation">.</span>kneighbors_graph<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> A<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#行-被测样本，这行是[0]。这行表示：对[0]来说，[0]和[1]是最近的2个邻居</span>
       <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#列-每个邻居（包括自身）</span>
       <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
</li>
</ul>
<h3 id="13-总结"><a href="#1-3-总结" class="headerlink" title="1.3 总结"></a>1.3 总结</h3><p>先计算出所有样本距离目标的<strong>距离</strong>，取最进的<strong>K个</strong>样本的平均数/中位数/众数/…</p>
<h2 id="2-knn填充数据"><a href="#2-KNN填充数据" class="headerlink" title="2. KNN填充数据"></a>2. KNN填充数据</h2><p>实际上，python中的KNNImputer库很好的利用knn实现了数据填充，<strong>直接上原理：</strong></p>
<blockquote>
<p>对于数据缺失的特征点，计算与其他数据特征间的距离，选取k个最小距离的数据特征点，把这k个数据特征中对应于目标特征点数据缺失的地方进行求<strong>均值</strong>，作为填充数据。</p>
</blockquote>
<p><strong>举个例子：</strong></p>
<pre class=" language-text"><code class="language-text">X = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]] = [n1 n2 n3 n4]
</code></pre>
<p><strong>含空值的欧式距离，如n1与n3：</strong></p>
<p><img data-src="/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/equation.svg" alt="img"></p>
<blockquote>
<p>参考文献：John K. Dixon, “Pattern Recognition with Partly Missing Data”, IEEE Transactions on Systems, Man, and Cybernetics, Volume: 9, Issue: 10, pp. 617 - 621, Oct. 1979.<span class="exturl" data-url="aHR0cHM6Ly9saW5rLnpoaWh1LmNvbS8/dGFyZ2V0PWh0dHA6Ly9pZWVleHBsb3JlLmllZWUub3JnL2Fic3RyYWN0L2RvY3VtZW50LzQzMTAwOTAv">http://ieeexplore.ieee.org/abs</span></p>
</blockquote>
<p>对应n1与n3的距离为：</p>
<p>![img](%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/equation (1).svg)</p>
<p>对应n1与n2的距离为：<br>$$<br>\sqrt{\frac{3}{2}\times ((1-3)^2+(2-4)^2)}=\sqrt{12}=3.464<br>$$</p>
<p><strong>python的nan_euclidean_distances函数可计算含空值的距离矩阵</strong>：</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> nan_euclidean_distances
X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>nan<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>nan<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
nan_euclidean_distances<span class="token punctuation">(</span>X<span class="token punctuation">,</span>X<span class="token punctuation">)</span>
</code></pre>
<p>计算出的距离矩阵为：</p>
<pre class=" language-python"><code class="language-python">array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">3.46410162</span><span class="token punctuation">,</span>  <span class="token number">6.92820323</span><span class="token punctuation">,</span> <span class="token number">11.29158979</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span> <span class="token number">3.46410162</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">3.46410162</span><span class="token punctuation">,</span>  <span class="token number">7.54983444</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span> <span class="token number">6.92820323</span><span class="token punctuation">,</span>  <span class="token number">3.46410162</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">3.46410162</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">11.29158979</span><span class="token punctuation">,</span>  <span class="token number">7.54983444</span><span class="token punctuation">,</span>  <span class="token number">3.46410162</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p><strong>python可直接用KNNImputer进行空值填充：</strong></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>impute <span class="token keyword">import</span> KNNImputer
X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>nan<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>nan<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
imputer <span class="token operator">=</span> KNNImputer<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
imputer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
</code></pre>
<p>KNNImputer中可选择k值来进行数据填充，这里选择2，填充结果：</p>
<pre class=" language-python"><code class="language-python">array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span> <span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span> <span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span> <span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">5.5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span> <span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">.</span> <span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span> <span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">.</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>

      <div class="tags">
          <a href="../../../../tags/%E7%AE%97%E6%B3%95/" rel="tag"><i class="ic i-tag"></i> 算法</a>
          <a href="../../../../tags/Python/" rel="tag"><i class="ic i-tag"></i> Python</a>
          <a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 机器学习</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">更新于</span>
    <time title="修改时间：2021-08-12 15:52:20" itemprop="dateModified" datetime="2021-08-12T15:52:20+08:00">2021-08-12</time>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> 赞赏</button>
  <p>请我喝[茶]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="../images/wechatpay.png" alt="宁理大神1996 微信支付">
        <p>微信支付</p>
      </div>
      
      <div>
        <img data-src="../images/alipay.png" alt="宁理大神1996 支付宝">
        <p>支付宝</p>
      </div>
      
      <div>
        <img data-src="../images/paypal.png" alt="宁理大神1996 贝宝">
        <p>贝宝</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>本文作者： </strong>宁理大神1996 <i class="ic i-at"><em>@</em></i>宁理大神 1996
  </li>
  <li class="link">
    <strong>本文链接：</strong>
    <a href="../../../../https:/nitgod1996.com/2021/06/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%A4%8D%E4%B9%A0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" title="西瓜书复习及其部分代码实现">https://nitgod1996.com/2021/06/10/西瓜书复习及代码实现/</a>
  </li>
  <li class="license">
    <strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="../../07/%E7%A8%80%E7%96%8F%E6%95%B0%E6%8D%AE%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva3.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giph4fomxoj20zk0m8axp.jpg" title="降低数据稀疏度的算法研究">
  <span class="type">上一篇</span>
  <span class="category"><i class="ic i-flag"></i> </span>
  <h3>降低数据稀疏度的算法研究</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="../../21/note/Python/jupyter/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva3.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giclh0m9pdj20zk0m8hdt.jpg" title="jupty使用方法">
  <span class="type">下一篇</span>
  <span class="category"><i class="ic i-flag"></i> </span>
  <h3>jupty使用方法</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="文章目录">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7"><span class="toc-number">1.</span> <span class="toc-text">数学符号</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-%E7%BB%AA%E8%AE%BA"><span class="toc-number">2.</span> <span class="toc-text">一、 绪论</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%9F%BA%E6%9C%AC%E6%9C%AF%E8%AF%AD%E5%8F%8A%E6%A6%82%E5%BF%B5"><span class="toc-number">2.1.</span> <span class="toc-text">1. 基本术语及概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.</span> <span class="toc-text">2. 激活函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-%E9%98%B6%E8%B7%83%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.1.</span> <span class="toc-text">2.1 阶跃函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-sigmoid%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.2.</span> <span class="toc-text">2.2 sigmoid函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-relu%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.3.</span> <span class="toc-text">2.3 ReLU函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-softmax%E5%87%BD%E6%95%B0%E6%9C%80%E5%90%8E%E4%B8%80%E5%B1%82%E8%BE%93%E5%87%BA%E5%B1%82%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.4.</span> <span class="toc-text">2.4 softmax函数（最后一层输出层的激活函数）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#25-%E5%87%BD%E6%95%B0%E5%9B%BE"><span class="toc-number">2.2.5.</span> <span class="toc-text">2.5 函数图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="toc-number">2.3.</span> <span class="toc-text">3. 梯度下降法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6"><span class="toc-number">2.4.</span> <span class="toc-text">梯度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">2.5.</span> <span class="toc-text">缺点：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.6.</span> <span class="toc-text">代码实现：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%AE%9A%E4%B9%89%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0"><span class="toc-number">2.6.0.1.</span> <span class="toc-text">1. 定义目标函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%B1%82%E5%87%BA%E6%A2%AF%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">2.6.0.2.</span> <span class="toc-text">2. 求出梯度函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E5%AE%9E%E7%8E%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="toc-number">2.6.0.3.</span> <span class="toc-text">3. 实现梯度下降法</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9"><span class="toc-number">3.</span> <span class="toc-text">二、 模型评估与选择</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E8%AF%AF%E5%B7%AE%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number">3.1.</span> <span class="toc-text">1. 误差与过拟合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="toc-number">3.2.</span> <span class="toc-text">2. 评估方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">三、 线性模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92linear-regression"><span class="toc-number">4.1.</span> <span class="toc-text">1. 线性回归（linear regression）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">4.1.1.</span> <span class="toc-text">1.1 算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#111-%E5%8D%95%E5%B1%9E%E6%80%A7%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">4.1.1.1.</span> <span class="toc-text">1.1.1 单属性线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#112-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">4.1.1.2.</span> <span class="toc-text">1.1.2 多元线性回归</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-python%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.1.2.</span> <span class="toc-text">1.2 Python代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AF%B9%E6%95%B0%E5%87%A0%E7%8E%87%E5%9B%9E%E5%BD%92%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">4.2.</span> <span class="toc-text">2. 对数几率回归（逻辑回归）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">4.2.1.</span> <span class="toc-text">2.1 与线性回归的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-sigmod%E5%87%BD%E6%95%B0"><span class="toc-number">4.2.2.</span> <span class="toc-text">2.2 sigmod函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">4.2.3.</span> <span class="toc-text">2.3 算法原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-%E4%BB%A3%E7%A0%81"><span class="toc-number">4.2.4.</span> <span class="toc-text">2.4 代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">5.</span> <span class="toc-text">四、 决策树</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%9D%E9%98%B6"><span class="toc-number">6.</span> <span class="toc-text">五、 神经网络初阶</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">6.1.</span> <span class="toc-text">1. 激活函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E9%98%B6%E8%B7%83%E5%87%BD%E6%95%B0"><span class="toc-number">6.1.1.</span> <span class="toc-text">1.1 阶跃函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-sigmoid%E5%87%BD%E6%95%B0"><span class="toc-number">6.1.2.</span> <span class="toc-text">1.2 sigmoid函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-relu%E5%87%BD%E6%95%B0"><span class="toc-number">6.1.3.</span> <span class="toc-text">1.3 ReLU函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-softmax%E5%87%BD%E6%95%B0%E6%9C%80%E5%90%8E%E4%B8%80%E5%B1%82%E8%BE%93%E5%87%BA%E5%B1%82%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">6.1.4.</span> <span class="toc-text">1.4 softmax函数（最后一层输出层的激活函数）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-%E5%87%BD%E6%95%B0%E5%9B%BE"><span class="toc-number">6.1.5.</span> <span class="toc-text">1.5 函数图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%B1%82%E6%AC%A1%E9%80%92%E8%BF%9B"><span class="toc-number">6.2.</span> <span class="toc-text">2. 神经网络的层次递进</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0"><span class="toc-number">6.3.</span> <span class="toc-text">3. 神经网络的学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1"><span class="toc-number">6.3.1.</span> <span class="toc-text">3.1 特征提取与算法设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">6.3.2.</span> <span class="toc-text">3.2 损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#321-%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE"><span class="toc-number">6.3.2.1.</span> <span class="toc-text">3.2.1 均方误差</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#322-%E4%BA%A4%E5%8F%89%E7%86%B5%E8%AF%AF%E5%B7%AE"><span class="toc-number">6.3.2.2.</span> <span class="toc-text">3.2.2 交叉熵误差</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0"><span class="toc-number">6.3.3.</span> <span class="toc-text">3.3 神经网络学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#34-%E8%AF%AF%E5%B7%AE%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%B1%82%E6%A2%AF%E5%BA%A6"><span class="toc-number">6.3.4.</span> <span class="toc-text">3.4 误差反向传播求梯度</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#341-%E5%85%B3%E4%BA%8Eaffine%E5%B1%82%E7%9A%84%E7%9F%A9%E9%98%B5%E5%8F%8D%E5%90%91%E6%B1%82%E5%AF%BC"><span class="toc-number">6.3.4.1.</span> <span class="toc-text">3.4.1 关于Affine层的矩阵反向求导</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#342-%E6%9C%80%E4%B8%8A%E6%B8%B8%E5%AF%BC%E6%95%B0%E7%94%9F%E6%88%90softmax_with_loss%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9B%B8%E5%AF%B9%E4%BA%8Esoftmax%E7%9A%84%E8%BE%93%E5%87%BAy%E7%9A%84%E4%BC%AA%E6%A2%AF%E5%BA%A6%E7%9F%A9%E9%98%B5"><span class="toc-number">6.3.4.2.</span> <span class="toc-text">3.4.2 最上游导数生成，softmax_with_loss，损失函数相对于softmax的输出y的伪梯度矩阵</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#343-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%B1%82%E6%A2%AF%E5%BA%A6%E4%BB%A3%E7%A0%81%E5%85%A8%E8%B2%8C"><span class="toc-number">6.3.4.3.</span> <span class="toc-text">3.4.3 反向传播求梯度代码全貌</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1"><span class="toc-number">6.4.</span> <span class="toc-text">4. 神经网络的代码设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-functionpy"><span class="toc-number">6.4.1.</span> <span class="toc-text">4.1 function.py</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#411-%E6%AD%A3%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">6.4.1.1.</span> <span class="toc-text">4.1.1 正向传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#412-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">6.4.1.2.</span> <span class="toc-text">4.1.2 反向传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#413-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.1.3.</span> <span class="toc-text">4.1.3 损失函数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-layerpy%E5%90%84%E5%B1%82%E7%9A%84%E7%B1%BB"><span class="toc-number">6.4.2.</span> <span class="toc-text">4.2 layer.py各层的类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#421-relu%E5%B1%82"><span class="toc-number">6.4.2.1.</span> <span class="toc-text">4.2.1 ReLU层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#422-sigmoid%E5%B1%82"><span class="toc-number">6.4.2.2.</span> <span class="toc-text">4.2.2 sigmoid层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#423-affine%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E4%B9%9F%E5%B0%B1%E6%98%AFawxb%E9%82%A3%E5%B1%82"><span class="toc-number">6.4.2.3.</span> <span class="toc-text">4.2.3 Affine层（全连接层，也就是a&#x3D;wx+b那层）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#424-%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">6.4.2.4.</span> <span class="toc-text">4.2.4 卷积层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#425-%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="toc-number">6.4.2.5.</span> <span class="toc-text">4.2.5 池化层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#426-softmax%E8%87%B3%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%B1%82"><span class="toc-number">6.4.2.6.</span> <span class="toc-text">4.2.6 softmax至损失函数层</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#43-neuralnet%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%B1%BB"><span class="toc-number">6.4.3.</span> <span class="toc-text">4.3 Neuralnet神经网络类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#431-%E7%B1%BB%E5%8F%98%E9%87%8F"><span class="toc-number">6.4.3.1.</span> <span class="toc-text">4.3.1 类变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#432-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%87%BD%E6%95%B0%E4%B8%BB%E8%A6%81%E7%94%A8%E4%BA%8E%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%8F%98%E9%87%8F"><span class="toc-number">6.4.3.2.</span> <span class="toc-text">4.3.2 初始化函数（主要用于定义类变量）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#433-%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.3.3.</span> <span class="toc-text">4.3.3 预测函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#434-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.3.4.</span> <span class="toc-text">4.3.4 损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#435-%E8%AE%A1%E7%AE%97%E7%B2%BE%E5%BA%A6"><span class="toc-number">6.4.3.5.</span> <span class="toc-text">4.3.5 计算精度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#436-%E6%B1%82%E6%A2%AF%E5%BA%A6"><span class="toc-number">6.4.3.6.</span> <span class="toc-text">4.3.6 求梯度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#437-%E4%BF%9D%E5%AD%98%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%E5%AE%8C%E5%90%8E%E4%BF%9D%E5%AD%98%E4%B8%8B%E6%9C%80%E7%BB%88%E6%9D%83%E9%87%8D%E7%AD%89%E5%8F%82%E6%95%B0"><span class="toc-number">6.4.3.7.</span> <span class="toc-text">4.3.7 保存参数（学习完后保存下最终权重等参数）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#438-%E5%8A%A0%E8%BD%BD%E5%8F%82%E6%95%B0%E9%A2%84%E6%B5%8B%E6%97%B6%E5%8A%A0%E8%BD%BD%E4%B9%8B%E5%89%8D%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E5%8F%82%E6%95%B0"><span class="toc-number">6.4.3.8.</span> <span class="toc-text">4.3.8 加载参数（预测时加载之前学习到的参数）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#44-trainer%E8%AE%AD%E7%BB%83%E7%B1%BB%E5%AD%A6%E4%B9%A0%E7%B1%BB"><span class="toc-number">6.4.4.</span> <span class="toc-text">4.4 Trainer训练类（学习类）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#441-%E7%B1%BB%E5%8F%98%E9%87%8F%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.4.1.</span> <span class="toc-text">4.4.1 类变量及初始化函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#442-%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0"><span class="toc-number">6.4.4.2.</span> <span class="toc-text">4.4.2 训练函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#443-%E6%9C%80%E7%BB%88%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0%E6%8F%90%E4%BE%9B%E7%BB%99%E5%A4%96%E7%95%8C%E7%9A%84api"><span class="toc-number">6.4.4.3.</span> <span class="toc-text">4.4.3 最终训练函数（提供给外界的API）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#45-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8A%A0%E8%BD%BDmnistpy"><span class="toc-number">6.4.5.</span> <span class="toc-text">4.5 数据集加载mnist.py</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#451-%E5%88%9D%E5%A7%8B%E5%8C%96%E6%89%80%E9%9C%80%E5%8F%82%E6%95%B0"><span class="toc-number">6.4.5.1.</span> <span class="toc-text">4.5.1 初始化所需参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#452-%E4%B8%8B%E8%BD%BD%E6%89%80%E9%9C%80%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">6.4.5.2.</span> <span class="toc-text">4.5.2 下载所需数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#453-%E8%A7%A3%E5%8E%8B%E6%89%93%E5%BC%80gzip%E6%96%87%E4%BB%B6"><span class="toc-number">6.4.5.3.</span> <span class="toc-text">4.5.3 解压打开gzip文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#454-%E5%B0%86%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BF%A1%E6%81%AF%E4%BF%9D%E5%AD%98%E5%9C%A8dict%E4%B8%AD"><span class="toc-number">6.4.5.4.</span> <span class="toc-text">4.5.4 将数据集信息保存在dict中</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#455-%E5%B0%86%E8%A7%A3%E5%8E%8B%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BF%9D%E5%AD%98%E5%88%B0%E6%9C%AC%E5%9C%B0"><span class="toc-number">6.4.5.5.</span> <span class="toc-text">4.5.5 将解压后的数据集保存到本地</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#456-%E7%9B%91%E7%9D%A3%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2"><span class="toc-number">6.4.5.6.</span> <span class="toc-text">4.5.6 监督数据格式转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#457-%E5%AF%B9%E5%A4%96%E6%8E%A5%E5%8F%A3api"><span class="toc-number">6.4.5.7.</span> <span class="toc-text">4.5.7 对外接口api</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#46-%E6%89%A7%E8%A1%8C%E4%B8%BB%E5%87%BD%E6%95%B0%E5%8C%85%E6%8B%AC%E5%9B%BE%E5%83%8F%E6%98%BE%E7%A4%BA"><span class="toc-number">6.4.6.</span> <span class="toc-text">4.6 执行主函数（包括图像显示）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#461-%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">6.4.6.1.</span> <span class="toc-text">4.6.1 读入数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#462-%E5%88%9B%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E8%B1%A1"><span class="toc-number">6.4.6.2.</span> <span class="toc-text">4.6.2 创建神经网络对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#463-%E5%88%9B%E5%BB%BA%E8%AE%AD%E7%BB%83%E5%AF%B9%E8%B1%A1"><span class="toc-number">6.4.6.3.</span> <span class="toc-text">4.6.3 创建训练对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#464-%E8%AE%AD%E7%BB%83%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%8F%82%E6%95%B0"><span class="toc-number">6.4.6.4.</span> <span class="toc-text">4.6.4 训练并保存参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#465-%E7%BB%98%E5%9B%BE"><span class="toc-number">6.4.6.5.</span> <span class="toc-text">4.6.5 绘图</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%80%BB%E7%BB%93"><span class="toc-number">6.5.</span> <span class="toc-text">5. 总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">7.</span> <span class="toc-text">六、 支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">7.1.</span> <span class="toc-text">正则化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81-knn%E7%AE%97%E6%B3%95"><span class="toc-number">8.</span> <span class="toc-text">十、 KNN算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-knn%E7%AE%97%E6%B3%95"><span class="toc-number">8.1.</span> <span class="toc-text">1. KNN算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E6%AD%A5%E9%AA%A4"><span class="toc-number">8.1.1.</span> <span class="toc-text">1.1 步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">8.1.2.</span> <span class="toc-text">1.2 代码实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-%E6%80%BB%E7%BB%93"><span class="toc-number">8.1.3.</span> <span class="toc-text">1.3 总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-knn%E5%A1%AB%E5%85%85%E6%95%B0%E6%8D%AE"><span class="toc-number">8.2.</span> <span class="toc-text">2. KNN填充数据</span></a></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="系列文章">
        <ul>
          <li><a href="../../../04/23/note/%E5%89%8D%E7%AB%AF/echarts/" rel="bookmark" title="echarts用法简单记录">echarts用法简单记录</a></li><li><a href="../../../05/10/note/software/maven%E5%A4%8D%E4%B9%A0/" rel="bookmark" title="maven复习">maven复习</a></li><li><a href="../../../05/10/note/hexo/Hexo%E6%90%AD%E5%BB%BAGitHub%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/" rel="bookmark" title="Hexo搭建GitHub静态博客">Hexo搭建GitHub静态博客</a></li><li><a href="../../../05/12/note/Linux/VMware%E5%AE%89%E8%A3%85%E4%B8%AD%E6%A0%87%E9%BA%92%E9%BA%9F/" rel="bookmark" title="VMware安装中标麒麟">VMware安装中标麒麟</a></li><li><a href="../../../05/13/note/Python/pandas/" rel="bookmark" title="Python机器学习库">Python机器学习库</a></li><li><a href="../../../05/17/note/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-Java%E8%B0%83%E7%94%A8Python%E8%84%9A%E6%9C%AC/" rel="bookmark" title="随笔-Java调用Python脚本">随笔-Java调用Python脚本</a></li><li><a href="../../../05/18/note/Java/java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E5%8F%8A%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/" rel="bookmark" title="java基础语法及特性">java基础语法及特性</a></li><li><a href="../../../05/20/note/%E9%9A%8F%E7%AC%94/%E5%87%86%E5%A4%87%E5%AD%A6%E4%B9%A0docker/" rel="bookmark" title="docker随手记">docker随手记</a></li><li><a href="../../../05/23/note/%E5%89%8D%E7%AB%AF/CSS/" rel="bookmark" title="CSS笔记及参考手册">CSS笔记及参考手册</a></li><li><a href="../../../05/26/note/%E5%89%8D%E7%AB%AF/html/" rel="bookmark" title="html常用功能手册">html常用功能手册</a></li><li><a href="../../../05/27/note/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-%E5%85%B3%E4%BA%8E%E5%89%8D%E7%AB%AF%E8%B0%83%E5%8F%96Python%E6%95%B0%E6%8D%AE/" rel="bookmark" title="前端调用Python数据">前端调用Python数据</a></li><li><a href="../../../05/27/note/%E5%89%8D%E7%AB%AF/JavaScript/" rel="bookmark" title="JavaScript基础语法">JavaScript基础语法</a></li><li><a href="../../../05/27/note/%E5%89%8D%E7%AB%AF/jQuery/" rel="bookmark" title="jQuery笔记">jQuery笔记</a></li><li><a href="../../../05/28/note/%E9%9A%8F%E7%AC%94/Python/%E9%9A%8F%E7%AC%94-%E5%88%A9%E7%94%A8Python%E6%89%B9%E9%87%8F%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6/" rel="bookmark" title="随笔-利用Python批量处理文件">随笔-利用Python批量处理文件</a></li><li><a href="../../../05/29/note/%E9%9A%8F%E7%AC%94/Python/%E9%9A%8F%E7%AC%94-%E5%88%A9%E7%94%A8Python%E5%A4%84%E7%90%86json/" rel="bookmark" title="随笔-利用Python处理json">随笔-利用Python处理json</a></li><li><a href="../../02/note/%E9%9A%8F%E7%AC%94/%E6%AF%8F%E6%97%A5%E4%B8%80%E7%AC%94/%E5%9F%BA%E4%BA%8EPython%E5%92%8Cecharts%E7%9A%84%E5%8A%A8%E6%80%81%E5%9B%BE/" rel="bookmark" title="每日一笔-基于Python和echarts的动态图">每日一笔-基于Python和echarts的动态图</a></li><li><a href="../../04/note/Python/Python%E8%AF%AD%E6%B3%95%E5%A4%8D%E4%B9%A0/" rel="bookmark" title="Python语法复习">Python语法复习</a></li><li class="active"><a href="" rel="bookmark" title="西瓜书复习及其部分代码实现">西瓜书复习及其部分代码实现</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="站点概览">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="宁理大神1996"
      data-src="../images/avatar.jpg">
  <p class="name" itemprop="name">宁理大神1996</p>
  <div class="description" itemprop="description">宁理大神的个人博客</div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="../archives/">
        <span class="count">28</span>
        <span class="name">文章</span>
      </a>
    </div>
    <div class="item categories">
      <a href="../categories/">
        <span class="count">14</span>
        <span class="name">分类</span>
      </a>
    </div>
    <div class="item tags">
      <a href="../tags/">
        <span class="count">22</span>
        <span class="name">标签</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3lvdXJuYW1l" title="https:&#x2F;&#x2F;github.com&#x2F;yourname"><i class="ic i-github"></i></span>
      <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;twitter.com&#x2F;yourname"><i class="ic i-twitter"></i></span>
      <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;yourname"><i class="ic i-zhihu"></i></span>
      <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPXlvdXJpZA==" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;yourid"><i class="ic i-cloud-music"></i></span>
      <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span>
      <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;about.me&#x2F;yourname"><i class="ic i-address-card"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="../index.html" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

    
  <li class="item">
    <a href="../about/" rel="section"><i class="ic i-user"></i>关于</a>
  </li>

    
  <li class="item">
    <a href="../archives/" rel="section"><i class="ic i-archive"></i>归档</a>
  </li>

    
  <li class="item">
    <a href="../categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

    
  <li class="item">
    <a href="../tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="../../07/%E7%A8%80%E7%96%8F%E6%95%B0%E6%8D%AE%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="../../21/note/Python/jupyter/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>随机文章</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/note/" title="分类于 笔记">笔记</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/note/%E5%89%8D%E7%AB%AF/" title="分类于 前端">前端</a>
</div>

    <span><a href="../../../05/23/note/%E5%89%8D%E7%AB%AF/CSS/" title="CSS笔记及参考手册">CSS笔记及参考手册</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
</div>

    <span><a href="../../21/note/Python/jupyter/" title="jupty使用方法">jupty使用方法</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/note/" title="分类于 笔记">笔记</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/note/%E5%89%8D%E7%AB%AF/" title="分类于 前端">前端</a>
</div>

    <span><a href="../../../05/27/note/%E5%89%8D%E7%AB%AF/jQuery/" title="jQuery笔记">jQuery笔记</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/note/" title="分类于 笔记">笔记</a>
</div>

    <span><a href="" title="西瓜书复习及其部分代码实现">西瓜书复习及其部分代码实现</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/note/" title="分类于 笔记">笔记</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/note/%E9%9A%8F%E7%AC%94/" title="分类于 随笔">随笔</a>
</div>

    <span><a href="../../../05/20/note/%E9%9A%8F%E7%AC%94/%E5%87%86%E5%A4%87%E5%AD%A6%E4%B9%A0docker/" title="docker随手记">docker随手记</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/note/" title="分类于 笔记">笔记</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/note/%E9%9A%8F%E7%AC%94/" title="分类于 随笔">随笔</a>
</div>

    <span><a href="../../../05/27/note/%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94-%E5%85%B3%E4%BA%8E%E5%89%8D%E7%AB%AF%E8%B0%83%E5%8F%96Python%E6%95%B0%E6%8D%AE/" title="前端调用Python数据">前端调用Python数据</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/computer-science/" title="分类于 计算机科学">计算机科学</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/computer-science/java/" title="分类于 Java">Java</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/computer-science/java/course-1/" title="分类于 零基础学 Java 语言 - 浙江大学 - 翁恺">零基础学 Java 语言 - 浙江大学 - 翁恺</a>
</div>

    <span><a href="../../../05/09/test/" title="my hexo">my hexo</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/note/" title="分类于 笔记">笔记</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/note/%E9%9A%8F%E7%AC%94/" title="分类于 随笔">随笔</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/note/%E9%9A%8F%E7%AC%94/%E6%AF%8F%E6%97%A5%E4%B8%80%E7%AC%94/" title="分类于 每日一笔">每日一笔</a>
</div>

    <span><a href="../../02/note/%E9%9A%8F%E7%AC%94/%E6%AF%8F%E6%97%A5%E4%B8%80%E7%AC%94/%E5%9F%BA%E4%BA%8EPython%E5%92%8Cecharts%E7%9A%84%E5%8A%A8%E6%80%81%E5%9B%BE/" title="每日一笔-基于Python和echarts的动态图">每日一笔-基于Python和echarts的动态图</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/note/" title="分类于 笔记">笔记</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/note/%E5%89%8D%E7%AB%AF/" title="分类于 前端">前端</a>
</div>

    <span><a href="../../../04/23/note/%E5%89%8D%E7%AB%AF/echarts/" title="echarts用法简单记录">echarts用法简单记录</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="../../../../categories/note/" title="分类于 笔记">笔记</a>
<i class="ic i-angle-right"></i>
<a href="../../../../categories/note/Python/" title="分类于 Python">Python</a>
</div>

    <span><a href="../../../05/13/note/Python/pandas/" title="Python机器学习库">Python机器学习库</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>最新评论</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2010 – 
    <span itemprop="copyrightYear">2021</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">宁理大神1996 @ nitgod1996</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="站点总字数">199k 字</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="站点阅读时长">3:01</span>
  </div>
  <div class="powered-by">
    基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2021/06/10/西瓜书复习及代码实现/',
    favicon: {
      show: "（●´3｀●）やれやれだぜ",
      hide: "(´Д｀)大変だ！"
    },
    search : {
      placeholder: "文章搜索",
      empty: "关于 「 ${query} 」，什么也没搜到",
      stats: "${time} ms 内找到 ${hits} 条结果"
    },
    valine: true,fancybox: true,copyright: '复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>


<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>


<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="../../../../js/app.js?v=0.2.5"></script>




<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
